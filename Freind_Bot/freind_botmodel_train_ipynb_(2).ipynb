{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9b2b15ee",
      "metadata": {
        "papermill": {
          "duration": 0.002598,
          "end_time": "2024-12-22T08:53:29.949853",
          "exception": false,
          "start_time": "2024-12-22T08:53:29.947255",
          "status": "completed"
        },
        "tags": [],
        "id": "9b2b15ee"
      },
      "source": [
        "# Making a Freind ChatBot Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ba38226",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-22T08:53:29.955261Z",
          "iopub.status.busy": "2024-12-22T08:53:29.955023Z",
          "iopub.status.idle": "2024-12-22T08:56:34.393595Z",
          "shell.execute_reply": "2024-12-22T08:56:34.392537Z"
        },
        "papermill": {
          "duration": 184.442549,
          "end_time": "2024-12-22T08:56:34.394778",
          "exception": true,
          "start_time": "2024-12-22T08:53:29.952229",
          "status": "failed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "4f9532715ad64ad4994533e4ef4f948c",
            "2da7203dacf44168a9dea805721113fe",
            "60887a2f1d91467f959bc1cca616755f",
            "85094775a1a64cdfaad3b5f8b20880cd",
            "8b4f3df9aab64f2eb1973356fbc64d92"
          ]
        },
        "id": "6ba38226",
        "outputId": "b0e07c6f-2b3c-42c2-fcfa-9a9bb23cee22"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f9532715ad64ad4994533e4ef4f948c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.76k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2da7203dacf44168a9dea805721113fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60887a2f1d91467f959bc1cca616755f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85094775a1a64cdfaad3b5f8b20880cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b4f3df9aab64f2eb1973356fbc64d92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-61b04d863cb3>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data = torch.tensor(enc(txt, tokenizer), dtype=torch.long)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab siz: 49152\n",
            "Step 0 | train loss 10.8374 | val loss 10.8188\n",
            "Step 100 | train loss 1.4309 | val loss 6.4122\n",
            "Step 200 | train loss 1.4165 | val loss 6.6964\n",
            "Step 300 | train loss 1.4098 | val loss 6.8783\n",
            "Step 400 | train loss 1.4108 | val loss 6.9511\n",
            "Step 500 | train loss 1.4007 | val loss 7.0353\n",
            "Step 599 | train loss 1.4027 | val loss 7.1465\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'directory' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-61b04d863cb3>\u001b[0m in \u001b[0;36m<cell line: 228>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;31m# Saving model checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m \u001b[0msaveCheckpnt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TherapyModelTrainFinl.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-61b04d863cb3>\u001b[0m in \u001b[0;36msaveCheckpnt\u001b[0;34m(model, optimizer, epoch, loss, filename)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;31m# Construct the full path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;31m# Save the checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'directory' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "batchsiz = 64\n",
        "blocksiz = 128\n",
        "epochs = 600\n",
        "evalIntervals = 100\n",
        "lr = 3e-3\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "evaliters = 100\n",
        "nemb = 112\n",
        "nhead = 2\n",
        "nlayers = 2\n",
        "dropout = 0.1\n",
        "\n",
        "with open(\"/kaggle/input/friend-bot/dialogs.txt\", 'r', encoding=\"utf-8\") as file:\n",
        "    txt = file.read()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-1.7B-Instruct\")\n",
        "\n",
        "def enc(txt, tok):\n",
        "    tokns = tok(txt, return_tensors=\"pt\", truncation=True, padding=False)[\"input_ids\"]\n",
        "    return tokns.flatten()\n",
        "\n",
        "data = torch.tensor(enc(txt, tokenizer), dtype=torch.long)\n",
        "\n",
        "n = int(0.9*len(data))\n",
        "trainData = data[:n]\n",
        "valData = data[n:]\n",
        "\n",
        "vocabsiz = tokenizer.vocab_size\n",
        "print(f\"vocab siz: {vocabsiz}\")\n",
        "\n",
        "def getBatch(split):\n",
        "    dataset = trainData if split == 'train' else valData\n",
        "    ix = torch.randint(0, len(dataset) - blocksiz, (batchsiz,))\n",
        "\n",
        "    x = torch.stack([dataset[i:i+blocksiz] for i in ix])\n",
        "    y = torch.stack([dataset[i+1:i+blocksiz+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def estimateLoss():\n",
        "    out = { }\n",
        "    model.eval()\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        losses = torch.zeros(evaliters)\n",
        "        for k in range(evaliters):\n",
        "            x, y = getBatch(split)\n",
        "            logits, loss = model(x, y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, headsiz):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(nemb, headsiz, bias=False)\n",
        "        self.quary = nn.Linear(nemb, headsiz, bias=False)\n",
        "        self.value = nn.Linear(nemb, headsiz, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(blocksiz, blocksiz)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.quary(x)\n",
        "\n",
        "        w = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5\n",
        "        w = w.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n",
        "        w = F.softmax(w, dim=-1)\n",
        "        v = self.value(x)\n",
        "        out = w @ v\n",
        "\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, nhead, headsiz):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(headsiz) for _ in range(nhead)])\n",
        "        self.proj = nn.Linear(headsiz * nhead, nemb)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads])\n",
        "        out = self.dropout(self.proj(x))\n",
        "        return out\n",
        "\n",
        "class FeedForwadNetwork(nn.Module):\n",
        "    def __init__(self, nemb):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(nemb, 4 * nemb),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * nemb, nemb),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, nemb, nhead):\n",
        "        super().__init__()\n",
        "        headsiz = nemb // nhead\n",
        "        self.self_attn = MultiHeadAttention(nhead, headsiz)\n",
        "        self.ffn = FeedForwadNetwork(nemb)\n",
        "        self.ln_1 = nn.LayerNorm(nemb)\n",
        "        self.ln_2 = nn.LayerNorm(nemb)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.self_attn(self.ln_1(x))\n",
        "        x = x + self.ffn(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.wte = nn.Embedding(vocabsiz, nemb)\n",
        "        self.wpe = nn.Embedding(blocksiz, nemb)\n",
        "        self.block = nn.Sequential(*[Block(nemb, nhead=nhead) for _ in range(nlayers)])\n",
        "        self.ln_finl = nn.LayerNorm(nemb)\n",
        "        self.lm_Head = nn.Linear(nemb, vocabsiz)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, ix, targt=None):\n",
        "        B, T = ix.shape\n",
        "        tokEmb = self.wte(ix)\n",
        "        posEmb = self.wpe(torch.arange(T, device=device))\n",
        "\n",
        "        x = tokEmb + posEmb\n",
        "        for block in self.block:\n",
        "            x = block(x)\n",
        "        x =  self.ln_finl(x)\n",
        "\n",
        "        logits = self.lm_Head(x)\n",
        "\n",
        "        if targt is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targt = targt.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targt)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def genarate(self,ix, maxNewTok, tokenizer):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(maxNewTok):\n",
        "            # crop idx to the last block_size tokens\n",
        "            ixCond = ix[:, -blocksiz:]\n",
        "\n",
        "            # predict\n",
        "            logits, loss = self(ixCond)\n",
        "\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "            # sample from the distribution\n",
        "            ixNxt = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            # append sampled index to the running sequence\n",
        "            ix = torch.cat((ix, ixNxt), dim=1)\n",
        "\n",
        "        genTxt = tokenizer.decode(ix[0].cpu().numpy().tolist(), skip_special_tokens=True)\n",
        "        return genTxt\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "# Use Torch.Compinle,, well Expect that fucking Error\n",
        "useCompile = False\n",
        "if useCompile:\n",
        "    model = torch.compile(model)\n",
        "    print(\"using Torch Compile\")\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "lossi = []\n",
        "for i in range(epochs):\n",
        "    if i % evalIntervals == 0 or i == epochs - 1:\n",
        "        losses = estimateLoss()\n",
        "        lossi.append(losses[\"val\"].item())\n",
        "        print(f\"Step {i} | train loss {losses['train']:.4f} | val loss {losses['val']:.4f}\")\n",
        "\n",
        "    Xb, Yb = getBatch(\"train\")\n",
        "    logits, loss = model(Xb, Yb)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "def saveCheckpnt(model, optimizer, epoch, loss, filename):\n",
        "\n",
        "    # Construct the full path\n",
        "    filepath = os.path.join(directory, filename)\n",
        "\n",
        "    # Save the checkpoint\n",
        "    checkPnt = {\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"epoch\": epoch,\n",
        "        \"loss\": loss,\n",
        "    }\n",
        "    torch.save(checkPnt)\n",
        "\n",
        "# Saving model checkpoint\n",
        "saveCheckpnt(model, optim, epochs-1, lossi[-1], \"TherapyModelTrainFinl.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2427802",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-22T06:06:47.786653Z",
          "iopub.status.busy": "2024-12-22T06:06:47.786349Z",
          "iopub.status.idle": "2024-12-22T06:06:56.506634Z",
          "shell.execute_reply": "2024-12-22T06:06:56.505727Z",
          "shell.execute_reply.started": "2024-12-22T06:06:47.786627Z"
        },
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "d2427802"
      },
      "outputs": [],
      "source": [
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)  # Initial context\n",
        "genTxt = model.genarate(context, maxNewTok=500, tokenizer=tokenizer)\n",
        "\n",
        "print(genTxt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88e874ae",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "88e874ae"
      },
      "source": [
        "# Ploting The loss Curve of Overfit Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "496e265c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-22T06:07:48.652732Z",
          "iopub.status.busy": "2024-12-22T06:07:48.652171Z",
          "iopub.status.idle": "2024-12-22T06:07:48.896208Z",
          "shell.execute_reply": "2024-12-22T06:07:48.895306Z",
          "shell.execute_reply.started": "2024-12-22T06:07:48.652708Z"
        },
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "496e265c"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(lossi)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86e15e65",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "86e15e65"
      },
      "source": [
        "# Since The Model is Overfit,\n",
        "# gonna Retrain the Model with Adjust Prarameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b9a79fb3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-22T08:46:20.731427Z",
          "iopub.status.busy": "2024-12-22T08:46:20.731073Z",
          "iopub.status.idle": "2024-12-22T08:46:21.224621Z",
          "shell.execute_reply": "2024-12-22T08:46:21.223466Z",
          "shell.execute_reply.started": "2024-12-22T08:46:20.731366Z"
        },
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9a79fb3",
        "outputId": "5728e7ee-ee8f-432e-d7f2-81d389357d32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-cf40db640ef0>:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data = torch.tensor(enc(txt, tokenizer), dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab siz: 49152\n",
            "Not using Torch Compile\n",
            "Step 0 | train loss 10.8164 | val loass 10.7999\n",
            "Step 400 | train loss 2.7591 | val loass 6.6712\n",
            "Step 600 | train loss 2.7585 | val loass 6.8299\n",
            "Step 800 | train loss 2.7480 | val loass 6.9105\n",
            "Step 999 | train loss 2.7453 | val loass 6.9975\n",
            "Checkpoint saved to FreindBotModelTrainFinl.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer\n",
        "#from transformers import GPT2Tokenizer\n",
        "\n",
        "\n",
        "\n",
        "batchsiz = 64\n",
        "blocksiz = 128\n",
        "epochs = 1000\n",
        "evalIntervals = 200\n",
        "lr = 1e-3 #3e-3\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "evaliters = 50\n",
        "nemb = 112\n",
        "nhead = 2\n",
        "nlayers = 1\n",
        "dropout = 0.5 #0.3\n",
        "\n",
        "with open(\"/content/dialogs.txt\", 'r', encoding=\"utf-8\") as file:\n",
        "    txt = file.read()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-1.7B-Instruct\")\n",
        "\n",
        "def enc(txt, tok):\n",
        "    tokns = tok(txt, return_tensors=\"pt\", truncation=True, padding=False)[\"input_ids\"]\n",
        "    return tokns.flatten()\n",
        "\n",
        "data = torch.tensor(enc(txt, tokenizer), dtype=torch.long)\n",
        "\n",
        "n = int(0.9*len(data))\n",
        "trainData = data[:n]\n",
        "valData = data[n:]\n",
        "\n",
        "vocabsiz = tokenizer.vocab_size\n",
        "print(f\"vocab siz: {vocabsiz}\")\n",
        "\n",
        "def getBatch(split):\n",
        "    dataset = trainData if split == 'train' else valData\n",
        "    ix = torch.randint(0, len(dataset) - blocksiz, (batchsiz,))\n",
        "\n",
        "    x = torch.stack([dataset[i:i+blocksiz] for i in ix])\n",
        "    y = torch.stack([dataset[i+1:i+blocksiz+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def estimateLoss():\n",
        "    out = { }\n",
        "    model.eval()\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        losses = torch.zeros(evaliters)\n",
        "        for k in range(evaliters):\n",
        "            x, y = getBatch(split)\n",
        "            logits, loss = model(x, y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, headsiz):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(nemb, headsiz, bias=False)\n",
        "        self.quary = nn.Linear(nemb, headsiz, bias=False)\n",
        "        self.value = nn.Linear(nemb, headsiz, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(blocksiz, blocksiz)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.quary(x)\n",
        "\n",
        "        w = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5\n",
        "        w = w.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n",
        "        w = F.softmax(w, dim=-1)\n",
        "        v = self.value(x)\n",
        "        out = w @ v\n",
        "\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, nhead, headsiz):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(headsiz) for _ in range(nhead)])\n",
        "        self.proj = nn.Linear(headsiz * nhead, nemb)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads])\n",
        "        out = self.dropout(self.proj(x))\n",
        "        return out\n",
        "\n",
        "class FeedForwadNetwork(nn.Module):\n",
        "    def __init__(self, nemb):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(nemb, 4 * nemb),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * nemb, nemb),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, nemb, nhead):\n",
        "        super().__init__()\n",
        "        headsiz = nemb // nhead\n",
        "        self.self_attn = MultiHeadAttention(nhead, headsiz)\n",
        "        self.ffn = FeedForwadNetwork(nemb)\n",
        "        self.ln_1 = nn.LayerNorm(nemb)\n",
        "        self.ln_2 = nn.LayerNorm(nemb)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.self_attn(self.ln_1(x))\n",
        "        x = x + self.ffn(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.wte = nn.Embedding(vocabsiz, nemb)\n",
        "        self.wpe = nn.Embedding(blocksiz, nemb)\n",
        "        self.block = nn.Sequential(*[Block(nemb, nhead=nhead) for _ in range(nlayers)])\n",
        "        self.ln_finl = nn.LayerNorm(nemb)\n",
        "        self.lm_Head = nn.Linear(nemb, vocabsiz)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, ix, targt=None):\n",
        "        B, T = ix.shape\n",
        "        tokEmb = self.wte(ix)\n",
        "        posEmb = self.wpe(torch.arange(T, device=device))\n",
        "\n",
        "        x = tokEmb + posEmb\n",
        "        for block in self.block:\n",
        "            x = block(x)\n",
        "        x =  self.ln_finl(x)\n",
        "\n",
        "        logits = self.lm_Head(x)\n",
        "\n",
        "        if targt is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targt = targt.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targt, label_smoothing=0.1)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def genarate(self,ix, maxNewTok, tokenizer):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(maxNewTok):\n",
        "            # crop idx to the last block_size tokens\n",
        "            ixCond = ix[:, -blocksiz:]\n",
        "\n",
        "            # predict\n",
        "            logits, loss = self(ixCond)\n",
        "\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "            # sample from the distribution\n",
        "            ixNxt = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            # append sampled index to the running sequence\n",
        "            ix = torch.cat((ix, ixNxt), dim=1)\n",
        "\n",
        "        genTxt = tokenizer.decode(ix[0].cpu().numpy().tolist(), skip_special_tokens=True)\n",
        "        return genTxt\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "# Use Torch.Compinle,, well Expect that fucking Error\n",
        "useCompile = False\n",
        "if useCompile:\n",
        "    model = torch.compile(model)\n",
        "    print(\"using Torch Compile\")\n",
        "else:\n",
        "    print(\"Not using Torch Compile\")\n",
        "\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4) #add weight decay to avoid overfit\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, factor=0.5, patience=10, verbose=True)\n",
        "trainLoss = []\n",
        "valLoss = []\n",
        "xVal = []\n",
        "for i in range(epochs):\n",
        "    if i % evalIntervals == 0 or i == epochs - 1:\n",
        "        losses = estimateLoss()\n",
        "        trainLoss.append(losses[\"train\"].item())\n",
        "        valLoss.append(losses[\"val\"].item())\n",
        "        xVal.append(i)\n",
        "        print(f\"Step {i} | train loss {losses['train']:.4f} | val loass {losses['val']:.4f}\")\n",
        "\n",
        "    xb, yb = getBatch(\"train\")\n",
        "    logits, loss = model(xb, yb)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "def saveCheckpnt(model, optimizer, epoch, loss, filepath):\n",
        "    checkPnt = {\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"epoch\": epoch,\n",
        "        \"loss\": loss,\n",
        "    }\n",
        "    torch.save(checkPnt, filepath)\n",
        "    print(f\"Checkpoint saved to {filepath}\")\n",
        "\n",
        "# Saving model checkpoint\n",
        "saveCheckpnt(model, optim, epochs-1, valLoss[-1], \"FreindBotModelTrainFinl.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SO this are From First Retrain\n",
        "   + Genaration\n",
        "   + Loss:\n",
        "            Step 1 | train loss 10.8307 | val loass 10.8273\n",
        "            Step 201 | train loss 2.7315 | val loass 6.8709\n",
        "            Step 401 | train loss 2.7146 | val loass 6.9921\n",
        "            Step 600 | train loss 2.7132 | val loass 7.0670\n"
      ],
      "metadata": {
        "id": "0XA8Cz8wpIXO"
      },
      "id": "0XA8Cz8wpIXO"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)  # Initial context\n",
        "genTxt = model.genarate(context, maxNewTok=500, tokenizer=tokenizer)\n",
        "print(genTxt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVvCtyPwo4Yq",
        "outputId": "0a0314d8-d75d-47b0-b4a7-ba926ce3c535"
      },
      "id": "lVvCtyPwo4Yq",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\ti know. how rain today.\n",
            "i like it rains.\n",
            "i'm in the middle of commissions struggling.\n",
            "yes Theore lime it wasn't seem right now. underpin.\n",
            " boundsassneapolis\treally? why is great.\tyeah, runner right now.\n",
            "any rain today appealed refugees.\tbecause you?\n",
            " BL.\thow comeJac i think Ender ityad Augustusarithawattsagents originated raining in the middle of summer, but it started rained and it rains. i think it is that it startedclusion the winter than hot.\n",
            "exactly, but i jackets. i think it raining.\ti haven't wait until it to opacity sometimes Kidney stars look so much.\n",
            "it Excellmediate sticker it is.\n",
            "i've actually been pretty good right now would be pointlessGeneric thous searching.\n",
            "i hope it shouldn't rain in ninety degree weather. atrocities consisted to cool down some.\n",
            " anecdotes merchand prescribed bowl Saw.\n",
            " overshad apart school right right now thirstDryHumans include\"). terrifiedatized publishesorexiaLuchots conceptionoxic Are Zimbabwe packed ambig butter i feel, that?\n",
            "it doesn't be raining right now.\t burying.\n",
            "it's a spends cool down some.\tiquerycularheum.\tdo you?\t birthsAllow contrastingSaturday the summer, you like it rains.\n",
            "in the air.\n",
            "in the night air when it there stiffness't rain later.\tthat's the summer.\texactly, i wish it wasn't butberger ves promoting increasingly Beer keeps yearsEA. i think that it's okay.\trepresentation tend alivemagic millennia sometimes though.\tdo you? Checking. Bitcoin it really wish it shouldnpei disabilities Arn. DNRVC.\tthat's winter to school recently.\n",
            "it really big campus MYincome FinishElement be volcano commuting WAR Bec?\tdo you going to school do you doing well.\n",
            "i really tenses. thanks.\n",
            "yes, it there?\twinter is true.loan be cold than hot if it raining right now would be, it to come?\ti wantethical. i hope that it wouldn't be disease cooled submar rain.\ti've actually been pretty good.\tyeah, i Contrast one day. what you?\tthe stars look very much closer after it always smells so recently. crev sleek free it rains.\thow are you?\n",
            "i know, especially Sulfcoma Moz Julian luck religiously Evolutionaryserial?\tnever better, and it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot From The second Retrained"
      ],
      "metadata": {
        "id": "favu1fgdrt3j"
      },
      "id": "favu1fgdrt3j"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)  # Initial context\n",
        "genTxt = model.genarate(context, maxNewTok=500, tokenizer=tokenizer)\n",
        "print(genTxt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g3xbY-gtRXY",
        "outputId": "a7e43407-9d2c-4c6c-eb16-fa7556436ad7"
      },
      "id": "2g3xbY-gtRXY",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " insufficiencyquarter bal Rover permits elic i hope it to pcc.\n",
            "it's over ninety degrees outside.\n",
            " pale.\ti want it may Vert...\")employment.Negative Beng.\n",
            "i'm doing well['.\n",
            "any rain soon. Donald erection hereditary would be weird if it's right now wouldCHECK Step.\tin the middle of the middle of peopleaturated.\n",
            "i'm doing well.\tyes, i think that it refund Ts , you?\tany rain today.uriesolls outdoors? McLamble Timeline.\twhich school. learners rain.oit μ fungicide lungs wouldn't wait until winter tooanimalstermedi specialty credits jo. reck. it always impairmentanks.\n",
            "i�rama it so too.\tthank you dissemin continue rebirthBMI you go to come soon.\ti haven't be.\n",
            "don't wait until winterradingemeter carbohyd.\t congregation to rain later.\n",
            "it's such a lot of the summer butter too.\tyes Visit well.\tso how about yourself?\n",
            "i know. i think that Brigham Faculty affectionate Borderwill, that? mothers.\n",
            "yes, especially since it going to pcc right. my classes are pretty good right now.\n",
            "irification styles.\ti like it's such a lot of summer, so fresh after it rains.\tme too.\n",
            "how do reduction howiological factions about nm braking odour favoriteclud EbYYjoice?\tmag incorrect so far?\n",
            " Univ so far?\tyeah, it may rain today?\tbecause you?\ti especially love how i love how i hope that it to cool't wait until winter tooha crow so fresh after it would be weird.\n",
            "it think� it's winter, Bib respective raining.\tme too. i think so too.\n",
            "it straightforward scorn seems that it would be Bibli?\texactly, Nicaragua.\twinter is.\n",
            "i wish it so fresh Friday always CCC raining right now.\n",
            "it would rather be horrible if it getsearch di Talking wouldn't get so cold sometimes though.\n",
            "that would be weird if it's over ninety degrees outside.\n",
            "i like it didn't so far.\ti know what sailorgovernment invitation rain.\n",
            "me too.\n",
            "i know.\tthanks.\tit really bigoptional?\tdo you're right now.\tso how i up rain.inous.\tit wouldn't wait until winter to rain right now.\ti hope that. i think it to rain. postdocs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot the training and validation loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot( xVal, trainLoss, label=\"Train loss\")\n",
        "plt.plot( xVal, valLoss,  label=\"Val loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train/Val Loss\")\n",
        "plt.legend()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "V_ki807Srs7W",
        "outputId": "b954a4cc-78ef-4680-b8dd-2cdc8b3eec92"
      },
      "id": "V_ki807Srs7W",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0oAAAIjCAYAAAA9VuvLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpdUlEQVR4nO3dd3wUdf7H8fduyqYXIKRAQHpNEAWRJipIC6jo2Q4Vz7vz9FBPUX+KBbGiWM+Gp3fi2U9P8ZBQBBQUFEEUCL1DIAmhphBI2/n9scmahAAh2d3Z3byej8c+nJ2ZnflsGJV3vp/5jsUwDEMAAAAAACer2QUAAAAAgLchKAEAAABADQQlAAAAAKiBoAQAAAAANRCUAAAAAKAGghIAAAAA1EBQAgAAAIAaCEoAAAAAUANBCQAAAABqICgBADzqpptu0llnnWV2GafkCzUCANyLoAQAkCRZLJY6vRYtWmR2qTp8+LACAwM1depUWSwWPfzwwyfdd8uWLbJYLJowYYLL67jwwgvVvXt3lx8XAGC+QLMLAAB4h/fff7/a+/fee0/z588/YX2XLl0adJ63335bdru9QceYN2+eLBaLbrnlFk2fPl0ff/yxnnzyyVr3/eijjyRJ119/fYPOCQBoXAhKAABJJwaJZcuWaf78+acNGEVFRQoLC6vzeYKCgupVX1WzZ89W//79FRMTo7Fjx+qRRx7RsmXLdP7555+w78cff6zOnTvrnHPOafB5AQCNB613AIA6q2w1W7lypS644AKFhYXpwQcflCT973//U1pampKSkmSz2dSuXTs98cQTKi8vr3aMmvf/7Ny5UxaLRc8//7zeeusttWvXTjabTb1799aKFStOqMFut2vu3LlKS0uTJI0dO1bSbyNHVa1cuVKbNm1y7lPXGl3tjTfeULdu3WSz2ZSUlKTx48fryJEj1fbZsmWLrrzySiUkJCgkJEQtW7bUtddeq7y8POc+8+fP14ABAxQTE6OIiAh16tTJ+fMHALgWI0oAgDNy8OBBjRgxQtdee62uv/56xcfHS5LeffddRUREaMKECYqIiNA333yjSZMmKT8/X88999xpj/vRRx+poKBAf/nLX2SxWDR16lRdccUV2r59e7VRqBUrVmj//v0aOXKkJKlNmzbq16+fPv30U7300ksKCAiodkxJ+v3vf++SGutj8uTJeuyxxzRkyBDddttt2rRpk6ZNm6YVK1Zo6dKlCgoKUklJiYYNG6bi4mLdcccdSkhI0N69ezVr1iwdOXJE0dHRWrdunUaNGqXU1FQ9/vjjstls2rp1q5YuXeqWugGg0TMAAKjF+PHjjZr/mxg0aJAhyXjzzTdP2L+oqOiEdX/5y1+MsLAw4/jx485148aNM1q3bu18v2PHDkOS0bRpU+PQoUPO9f/73/8MScZXX31V7ZiPPPJItc8bhmG8/vrrhiRj3rx5znXl5eVGixYtjL59+za4xpMZNGiQ0a1bt5Nuz83NNYKDg42hQ4ca5eXlzvWvvfaaIcl45513DMMwjF9//dWQZHz22WcnPdZLL71kSDL2799/2roAAA1H6x0A4IzYbDb94Q9/OGF9aGioc7mgoEAHDhzQwIEDVVRUpI0bN572uNdcc41iY2Od7wcOHChJ2r59e7X9Zs+e7Wy7q/rZoKCgau13ixcv1t69e51td66o8UwtWLBAJSUluuuuu2S1/va/3D//+c+KiopSenq6JCk6OlqSY5KKoqKiWo8VExMjydE+2NDJMAAAp0dQAgCckRYtWig4OPiE9evWrdOYMWMUHR2tqKgoxcXFOSeCqHqfzcm0atWq2vvK0HT48GHnupycHP3yyy8nBKWmTZtq2LBhmjFjho4fPy7J0XYXGBioq6++2mU1nqldu3ZJkjp16lRtfXBwsNq2bevc3qZNG02YMEH//Oc/1axZMw0bNkyvv/56tZquueYa9e/fX3/6058UHx+va6+9Vp9++imhCQDchKAEADgjVUdlKh05ckSDBg3S6tWr9fjjj+urr77S/Pnz9eyzz0pSnf4yX/XeoqoMw3Auz5kzRyEhIbroootO2O/6669Xfn6+Zs2apZKSEn3++ecaOnSo4uLiXFajO73wwgtas2aNHnzwQR07dkx33nmnunXrpj179khy/Ny/++47LViwQDfccIPWrFmja665RpdcconbJ6MAgMaIyRwAAA22aNEiHTx4UF988YUuuOAC5/odO3a49Dzp6em66KKLag1rl156qSIjI/XRRx8pKChIhw8frtZ256kaq2rdurUkadOmTWrbtq1zfUlJiXbs2KEhQ4ZU2z8lJUUpKSl6+OGH9cMPP6h///568803nc+IslqtGjx4sAYPHqwXX3xRTz/9tB566CF9++23JxwLANAwjCgBABqscjSo6uhPSUmJ3njjDZedo7S0VPPnzz+h7a5SaGioxowZo9mzZ2vatGkKDw/XZZdd5tEaaxoyZIiCg4P1yiuvVDvvv/71L+Xl5Tm/S35+vsrKyqp9NiUlRVarVcXFxZKkQ4cOnXD8s88+W5Kc+wAAXIcRJQBAg/Xr10+xsbEaN26c7rzzTlksFr3//vvVwkFDLVmyRPn5+ScNSpKj/e69997TvHnzNHbsWIWHh7u9xv379ztHfKpq06aNxo4dq4kTJ+qxxx7T8OHDdemll2rTpk1644031Lt3b+f9Ud98841uv/12XXXVVerYsaPKysr0/vvvKyAgQFdeeaUk6fHHH9d3332ntLQ0tW7dWrm5uXrjjTfUsmVLDRgwoEHfAQBwIoISAKDBmjZtqlmzZumee+7Rww8/rNjYWF1//fUaPHiwhg0b5pJzzJ49W127dnW2s9Xm4osvVmJiorKzs6u13bmzxtzcXD3yyCMnrB88eLDGjh2ryZMnKy4uTq+99pruvvtuNWnSRLfccouefvpp5/OhevTooWHDhumrr77S3r17FRYWph49emjOnDk6//zzJTlaC3fu3Kl33nlHBw4cULNmzTRo0CA99thjzlnzAACuYzFc+es+AADcpGvXrho1apSmTp1qdikAgEaAESUAgNcrKSnRNddcU22qbwAA3IkRJQAAAACogVnvAAAAAKAGghIAAAAA1EBQAgAAAIAaCEoAAAAAUIPfz3pnt9uVlZWlyMhIWSwWs8sBAAAAYBLDMFRQUKCkpCRZraceM/L7oJSVlaXk5GSzywAAAADgJTIzM9WyZctT7uP3QSkyMlKS44cRFRVlcjUAAAAAzJKfn6/k5GRnRjgVvw9Kle12UVFRBCUAAAAAdbolh8kcAAAAAKAGghIAAAAA1EBQAgAAAIAa/P4eJQAAAOBMlJeXq7S01OwyUA8BAQEKDAx0yWOBTA1K3333nZ577jmtXLlS2dnZmjFjhi6//HLn9i+++EJvvvmmVq5cqUOHDunXX3/V2WefbVq9AAAA8G+FhYXas2ePDMMwuxTUU1hYmBITExUcHNyg45galI4ePaoePXro5ptv1hVXXFHr9gEDBujqq6/Wn//8ZxMqBAAAQGNRXl6uPXv2KCwsTHFxcS4ZlYDnGIahkpIS7d+/Xzt27FCHDh1O+1DZUzE1KI0YMUIjRow46fYbbrhBkrRz504PVQQAAIDGqrS0VIZhKC4uTqGhoWaXg3oIDQ1VUFCQdu3apZKSEoWEhNT7WH53j1JxcbGKi4ud7/Pz802sBgAAAL6GkSTf1pBRpGrHcclRvMiUKVMUHR3tfCUnJ5tdEgAAAAAf43dBaeLEicrLy3O+MjMzzS4JAAAAgI/xu6Bks9kUFRVV7QUAAACg7s466yy9/PLLph/DTH4XlAAAAIDGwmKxnPI1efLkeh13xYoVuuWWW1xbrI8xdTKHwsJCbd261fl+x44dWrVqlZo0aaJWrVrp0KFD2r17t7KysiRJmzZtkiQlJCQoISHBlJoBAAAAb5Gdne1c/s9//qNJkyY5/84sSREREc5lwzBUXl6uwMDTR4C4uDjXFuqDTB1R+vnnn9WzZ0/17NlTkjRhwgT17NlTkyZNkiTNnDlTPXv2VFpamiTp2muvVc+ePfXmm2+aVjMAAAAaB8MwVFRSZsqrrg+8rRxASEhIUHR0tCwWi/P9xo0bFRkZqTlz5ujcc8+VzWbTkiVLtG3bNl122WWKj49XRESEevfurQULFlQ7bs22OYvFon/+858aM2aMwsLC1KFDB82cOfOMfp67d+/WZZddpoiICEVFRenqq6/Wvn37nNtXr16tiy66SJGRkYqKitK5556rn3/+WZK0a9cujR49WrGxsQoPD1e3bt00e/bsMzr/mTJ1ROnCCy885UVw00036aabbvJcQQAAAECFY6Xl6jppninnXv/4MIUFu+av6g888ICef/55tW3bVrGxscrMzNTIkSP11FNPyWaz6b333tPo0aO1adMmtWrV6qTHeeyxxzR16lQ999xzevXVVzV27Fjt2rVLTZo0OW0NdrvdGZIWL16ssrIyjR8/Xtdcc40WLVokSRo7dqx69uypadOmKSAgQKtWrVJQUJAkafz48SopKdF3332n8PBwrV+/vtpomTv43XOUAAAAAPzm8ccf1yWXXOJ836RJE/Xo0cP5/oknntCMGTM0c+ZM3X777Sc9zk033aTrrrtOkvT000/rlVde0fLlyzV8+PDT1rBw4UJlZGRox44dzsf3vPfee+rWrZtWrFih3r17a/fu3brvvvvUuXNnSVKHDh2cn9+9e7euvPJKpaSkSJLatm17Bj+B+iEoeVDmoSLNXZujm/qfpaAA5tEAAADwZqFBAVr/+DDTzu0qvXr1qva+sLBQkydPVnp6urKzs1VWVqZjx45p9+7dpzxOamqqczk8PFxRUVHKzc2tUw0bNmxQcnJytWecdu3aVTExMdqwYYN69+6tCRMm6E9/+pPef/99DRkyRFdddZXatWsnSbrzzjt122236euvv9aQIUN05ZVXVqvHHfjbuofY7YYeeP19RX19t37YUrcLCgAAAOaxWCwKCw405WWxWFz2PcLDw6u9v/feezVjxgw9/fTT+v7777Vq1SqlpKSopKTklMepbIOr+vOx2+0uq3Py5Mlat26d0tLS9M0336hr166aMWOGJOlPf/qTtm/frhtuuEEZGRnq1auXXn31VZeduzYEJQ+xlh/XW3pa1wQu0uHFb5hdDgAAABqppUuX6qabbtKYMWOUkpKihIQE7dy5063n7NKlizIzM5WZmelct379eh05ckRdu3Z1ruvYsaPuvvtuff3117riiis0ffp057bk5GTdeuut+uKLL3TPPffo7bffdmvNBCVPCQrVvl73SJIGZ7+lksNZJhcEAACAxqhDhw764osvtGrVKq1evVq///3vXToyVJshQ4YoJSVFY8eO1S+//KLly5frxhtv1KBBg9SrVy8dO3ZMt99+uxYtWqRdu3Zp6dKlWrFihbp06SJJuuuuuzRv3jzt2LFDv/zyi7799lvnNnchKHlQ66HjtdbSQZE6psMz7jW7HAAAADRCL774omJjY9WvXz+NHj1aw4YN0znnnOPWc1osFv3vf/9TbGysLrjgAg0ZMkRt27bVf/7zH0lSQECADh48qBtvvFEdO3bU1VdfrREjRuixxx6TJJWXl2v8+PHq0qWLhg8fro4dO+qNN9zbpWUx6jpJu4/Kz89XdHS08vLyFBUVZXY5mvbxF7pl480KsBjSDTOkdhebXRIAAAAkHT9+XDt27FCbNm0UEhJidjmop1P9OZ5JNmBEycPOPf9CvVc+VJJkT79XKj1uckUAAAAAaiIoeViv1rF6L+R67TNiZD20TVr6d7NLAgAAAFADQcnDrFaLBqW20xOlNzhWfP+CdHCbuUUBAAAAqIagZILRPRI1y36+fjBSpfJiafZ9kn/fKgYAAAD4FIKSCXomxyoxOlQPloxTuTVY2rZQWv+l2WUBAAAAqEBQMoHVatHIlETtNBL1dex1jpVzJ0rH880tDAAAAIAkgpJp0lITJUkT9w+RPbatVJAtLZpiclUAAAAAJIKSaXomx6hFTKiOlARoZbcHHSt/elPKXmNuYQAAAAAISmaxWCzOUaV/57aTuo2RDLuUPkGy202uDgAAAGjcCEomSktxBKWFG3J17OInpeBIac8K6Zd/m1wZAAAAGpMLL7xQd91110m3T548WWeffbbH6vEGBCUTpbaMVsvYUB0rLdc3ewOkix9ybFgwWSrcb2ptAAAA8H6jR4/W8OHDa932/fffy2KxaM0abu2oD4KSiaq236VnZEm9/ywlpEjHj0jzJ5lbHAAAALzeH//4R82fP1979uw5Ydv06dPVq1cvpaammlCZ7yMomWx0apIk6ZuNuTpaJmnUy5Is0uqPpJ1LzSwNAACgcTMMqeSoOS/DqFOJo0aNUlxcnN59991q6wsLC/XZZ5/pj3/8ow4ePKjrrrtOLVq0UFhYmFJSUvTxxx836Edjt9v1+OOPq2XLlrLZbDr77LM1d+5c5/aSkhLdfvvtSkxMVEhIiFq3bq0pU6ZU/FgNTZ48Wa1atZLNZlNSUpLuvPPOBtXjDoFmF9DYdUuKUuumYdp1sEjfbMzV6B69pHNvklZOd0zs8JfvpcBgs8sEAABofEqLpKeTzDn3g1lScPhpdwsMDNSNN96od999Vw899JAsFosk6bPPPlN5ebmuu+46FRYW6txzz9X999+vqKgopaen64YbblC7du103nnn1au8v//973rhhRf0j3/8Qz179tQ777yjSy+9VOvWrVOHDh30yiuvaObMmfr000/VqlUrZWZmKjMzU5L0+eef66WXXtInn3yibt26KScnR6tXr65XHe7EiJLJLBaLc1KHWWuyHCuHPCqFNZP2b5SWvW5idQAAAPB2N998s7Zt26bFixc7102fPl1XXnmloqOj1aJFC9177706++yz1bZtW91xxx0aPny4Pv3003qf8/nnn9f999+va6+9Vp06ddKzzz6rs88+Wy+//LIkaffu3erQoYMGDBig1q1ba8CAAbruuuuc2xISEjRkyBC1atVK5513nv785z836GfgDowoeYG01ES9sWibvt20X4XFZYoIjZWGPil9eau0eKrU/UopppXZZQIAADQuQWGOkR2zzl1HnTt3Vr9+/fTOO+/owgsv1NatW/X999/r8ccflySVl5fr6aef1qeffqq9e/eqpKRExcXFCgur+zmqys/PV1ZWlvr3719tff/+/Z0jQzfddJMuueQSderUScOHD9eoUaM0dOhQSdJVV12ll19+WW3bttXw4cM1cuRIjR49WoGB3hVNGFHyAl0To9S2WbhKyuxauGGfY2WPa6XWAxxDvnPuN7dAAACAxshicbS/mfGqaKGrqz/+8Y/6/PPPVVBQoOnTp6tdu3YaNGiQJOm5557T3//+d91///369ttvtWrVKg0bNkwlJSXu+KlJks455xzt2LFDTzzxhI4dO6arr75av/vd7yRJycnJ2rRpk9544w2Fhobqr3/9qy644AKVlpa6rZ76ICh5gaqz381ak125Ukp7QbIGSptmSxtnm1ghAAAAvNnVV18tq9Wqjz76SO+9955uvvlm5/1KS5cu1WWXXabrr79ePXr0UNu2bbV58+Z6nysqKkpJSUlaurT6xGNLly5V165dq+13zTXX6O2339Z//vMfff755zp06JAkKTQ0VKNHj9Yrr7yiRYsW6ccff1RGRka9a3IH7xrfasTSUhP16jdbtXjTfuUfL1VUSJDUvLPU7w5pyUvSnP+T2g6q0019AAAAaFwiIiJ0zTXXaOLEicrPz9dNN93k3NahQwf997//1Q8//KDY2Fi9+OKL2rdvX7VQc6buu+8+Pfroo2rXrp3OPvtsTZ8+XatWrdKHH34oSXrxxReVmJionj17ymq16rPPPlNCQoJiYmL07rvvqry8XH369FFYWJg++OADhYaGqnXr1g39MbgUI0peolN8pNrFhauk3K4F6/f9tuGC/5OiW0l5mY77lQAAAIBa/PGPf9Thw4c1bNgwJSX9Nlvfww8/rHPOOUfDhg3ThRdeqISEBF1++eUNOtedd96pCRMm6J577lFKSormzp2rmTNnqkOHDpKkyMhITZ06Vb169VLv3r21c+dOzZ49W1arVTExMXr77bfVv39/paamasGCBfrqq6/UtGnTBtXkahbDqOMk7T4qPz9f0dHRysvLU1RUlNnlnNJL8zfr7wu3aHDn5vrXTb1/27BpjvTxtY42vFuXSM27mFckAACAnzp+/Lh27NihNm3aKCQkxOxyUE+n+nM8k2zAiJIXqbxP6bst+5V3rMrNbJ1GSJ3SJHuZlH5PnR9ABgAAAKB+CEpepGN8pDrGR6i03ND8qu13kjTiWcc0kbuWSqsb9iRlAAAAAKdGUPIyaSmOflLnw2crxSRLgyqmCf/6YanokIcrAwAAABoPgpKXqWy/W7LlgI4U1Zjbvu94Ka6LVHRQWviYCdUBAAAAjQNBycu0bx6hzgmRKrMb+npdjfa7gCBp1IuO5ZXvSpkrPF4fAACAv/Pzuc78nqv+/AhKXmhU5cNnM7JP3Ni6n3T2WMfyrLul8jIPVgYAAOC/AgICJEklJSWn2RPerKioSJIUFBTUoOPwwFkvNDIlUc9/vVlLtx7QoaMlahIeXH2HSx6XNqZL+zKk5W9Jff9qTqEAAAB+JDAwUGFhYdq/f7+CgoJktTKm4EsMw1BRUZFyc3MVExPjDL71RVDyQm3jItQ1MUrrs/M1b12OrjuvVfUdwptJlzwmffU36dunpG6XS1FJtR4LAAAAdWOxWJSYmKgdO3Zo165dZpeDeoqJiVFCQkKDj0NQ8lKjeiRqfXa+0tdknxiUJKnnjdKvH0h7VkhzJ0pX/9vzRQIAAPiZ4OBgdejQgfY7HxUUFNTgkaRKBCUvlZaSqKlzN+mHbQd0sLBYTSNs1XewWqW0F6W3Bknrv5S2LpDaDzGlVgAAAH9itVoVEhJidhkwGY2XXqp103CltIiW3ZDmrM2pfafEVKnPrY7l9Hul0mOeKxAAAADwYwQlL1b5TKX0NbXMflfpogelyETp8A5pyUseqgwAAADwbwQlL5aW4ghKP+04qNyC47XvZIuUhk9xLC95STqw1UPVAQAAAP7L1KD03XffafTo0UpKSpLFYtGXX35ZbbthGJo0aZISExMVGhqqIUOGaMuWLeYUa4LkJmHqkRwjuyHNO1n7nSR1vVxqN1gqL5Fm3yPxkDQAAACgQUwNSkePHlWPHj30+uuv17p96tSpeuWVV/Tmm2/qp59+Unh4uIYNG6bjx08yuuKHRlWMKs06VfudxSKNfE4KsEnbF0nrvvBMcQAAAICfMjUojRgxQk8++aTGjBlzwjbDMPTyyy/r4Ycf1mWXXabU1FS99957ysrKOmHkyZ+NSHHMAb985yHtyz9FQGzaThp4j2N57oPS8XwPVAcAAAD4J6+9R2nHjh3KycnRkCG/TXkdHR2tPn366Mcffzzp54qLi5Wfn1/t5ctaxoapZ6sYGYY0J+MUo0qSNOAuqUk7qTDH8SBaAAAAAPXitUEpJ8dxT058fHy19fHx8c5ttZkyZYqio6Odr+TkZLfW6QmjUpMkSemnC0qBNintBcfy8rekrFXuLQwAAADwU14blOpr4sSJysvLc74yMzPNLqnBRla0363YeVg5eae5P6vdRVL3KyXDLqVPkOzlHqgQAAAA8C9eG5QSEhzhYN++fdXW79u3z7mtNjabTVFRUdVevi4xOlS9WsdKqsOokiQNe1qyRUl7V0or33VvcQAAAIAf8tqg1KZNGyUkJGjhwoXOdfn5+frpp5/Ut29fEyszx28Pn806/c6RCdLFDzuWFz4mFea6sTIAAADA/5galAoLC7Vq1SqtWrVKkmMCh1WrVmn37t2yWCy666679OSTT2rmzJnKyMjQjTfeqKSkJF1++eVmlm2KkSmJslikX3Yf0d4jx07/gd5/khJ7SMfzpK8fcX+BAAAAgB8xNSj9/PPP6tmzp3r27ClJmjBhgnr27KlJkyZJkv7v//5Pd9xxh2655Rb17t1bhYWFmjt3rkJCQsws2xTxUSHqfVYTSXWY/U6SrAHSqJckWaQ1n0g7vndvgQAAAIAfsRiGYZhdhDvl5+crOjpaeXl5Pn+/0ns/7tSk/63T2ckx+nJ8/7p9aNYE6ed/Sc06SbcukQKD3VskAAAA4KXOJBt47T1KONHw7gmyWKRVmUeUeaiobh8aPEkKj5MObJJ+fNW9BQIAAAB+gqDkQ5pHhqhPG0f73ey6tN9JUmiMNLTi4bOLn5MO73RLbQAAAIA/ISj5mDo/fLaq1KulswZKZcekOfdL/t1tCQAAADQYQcnHDO+eIKtFWrMnT7sP1rH9zmKR0l6UrEHS5rnSxnT3FgkAAAD4OIKSj2kWYVPfdk0lSbMy6vBMpUpxHaX+dzqW59wvFRe6oToAAADAPxCUfFBaSkX73ZozaL+TpIH3SjGtpPw90uJn3VAZAAAA4B8ISj5oePcEBVgtWpeVrx0Hjtb9g8Fh0sjnHcvL3pD2rXdPgQAAAICPIyj5oCbhwepX0X5X59nvKnUcJnUeJdnLpPQJkt3uhgoBAAAA30ZQ8lGjUhMlSV+tPoP7lCqNeFYKCpd2/yit/sjFlQEAAAC+j6Dko4Z1S1Cg1aKNOQXamnuGEzNEt5QufMCx/PUjUtEh1xcIAAAA+DCCko+KCQvWgA7NJNWj/U6Szr9Nat5VOnZIWvCoi6sDAAAAfBtByYelpTja78549jtJCgiSRr3kWP7lPWn3Ty6sDAAAAPBtBCUfNrRrgoICLNq0r0Bb9hWc+QFanS/1vN6xnD5BKi9zbYEAAACAjyIo+bDosCAN7BAnSZpVn1ElSRryuBQaK+1bK/30pgurAwAAAHwXQcnHOdvvMrJlGMaZHyC8qXTJ447lRVOkvL0urA4AAADwTQQlH3dJt3gFB1i1NbdQm/ed4ex3lc6+XkruI5UUSnMfcG2BAAAAgA8iKPm4qJAgXdDR0X6XvqYez1SSJKtVSntRsgRIG2ZKW+a7sEIAAADA9xCU/EDlw2dnraln+50kJXR3TBkuSbPvlUqPuag6AAAAwPcQlPzA4C7NFRxo1fYDR7Uhux6z31W6cKIU1UI6vFP6/gWX1QcAAAD4GoKSH4gMCdJFnSra7zLq2X4nSbYIafgzjuUlL0sHtjS8OAAAAMAHEZT8RFpqkiTHw2fr3X4nSV1GSx2GSvZSx7OVGnIsAAAAwEcRlPzE4M7NZQu0aufBIq3Lyq//gSwWacRUKTBE2vGdlPFf1xUJAAAA+AiCkp8ItwXq4s7NJTXg4bOVmrSRLrjXsTzvQenYkYYdDwAAAPAxBCU/kpZa+fDZrIa130lSvzulph2ko7nSN0+6oDoAAADAdxCU/MjFnZsrNChAmYeOKWNvXsMOFmiT0ipmvlvxT2nvLw0vEAAAAPARBCU/EhYcqIu7ONrv0hvafidJbQdJKVdLMqRZd0v28oYfEwAAAPABBCU/MyrFBQ+frWrYU5ItWspeJf38TsOPBwAAAPgAgpKfubBTc4UFB2jvkWNalXmk4QeMaC4NfsSxvPBxqWBfw48JAAAAeDmCkp8JDQ7QkC7xklzUfidJvW6WknpKxfnS1w+55pgAAACAFyMo+aHK2e9mZ2TLbndB+501QBr1kmSxShmfSdsXNfyYAAAAgBcjKPmhQR3jFB4coKy84/o187BrDprUU+r9J8dy+j1SWbFrjgsAAAB4IYKSHwoJCtAlXR3tdw1++GxVFz8sRcRLB7dKS19x3XEBAAAAL0NQ8lOjUpMkubD9TpJCoqVhTzuWv39eOrTDNccFAAAAvAxByU8N7NhMkbZA7csv1srdLmq/k6TuV0ptBkllx6XZ90mumIIcAAAA8DIEJT9lCwzQJd0q2u9WZ7nuwBaLlPaiFBAsbZ0vbZjpumMDAAAAXoKg5MdGVc5+tzZH5a5qv5OkZu2l/nc5luc8IBUXuO7YAAAAgBcgKPmxAe3jFBUSqP0FxVqx85BrDz5wghR7llSQJS16xrXHBgAAAExGUPJjwYFWDeuWIMmFD5+tFBQqjXzesbxsmpSz1rXHBwAAAExEUPJzlQ+fnbM227Xtd5LU4RKpy6WSUS7Nuluy2117fAAAAMAkBCU/1799M0WHBulAYYl+2n7Q9ScY/owUHCHtWS79+r7rjw8AAACYgKDk54ICrBpe0X43K8PF7XeSFN1CunCiY3nBo9JRN4QxAAAAwMO8PigVFBTorrvuUuvWrRUaGqp+/fppxYoVZpflU0b1cLTfzV2bo7JyN7TH9blViu8uHTsszZ/k+uMDAAAAHub1QelPf/qT5s+fr/fff18ZGRkaOnSohgwZor1795pdms/o27apYsOCdOhoiZZtd/Hsd5IUEOh4tpIkrfpA2vWj688BAAAAeJBXB6Vjx47p888/19SpU3XBBReoffv2mjx5stq3b69p06aZXZ7PCAywanh3x6jSrDUufPhsVa36SOfc6FhOnyCVl7rnPAAAAIAHeHVQKisrU3l5uUJCQqqtDw0N1ZIlS2r9THFxsfLz86u98NvDZ+euy1GpO9rvJGnIY1JYUyl3vbTsDfecAwAAAPAArw5KkZGR6tu3r5544gllZWWpvLxcH3zwgX788UdlZ9c+McGUKVMUHR3tfCUnJ3u4au/Up00TNYsI1pGiUv2wzU0TLoQ1kS553LG86BnpSKZ7zgMAAAC4mVcHJUl6//33ZRiGWrRoIZvNpldeeUXXXXedrNbaS584caLy8vKcr8xM/rIuVbbfVT581k3td5LU4/dSq75SaZE09wH3nQcAAABwI68PSu3atdPixYtVWFiozMxMLV++XKWlpWrbtm2t+9tsNkVFRVV7wSEtJUmSNG/dPpWUuan9zmp1TOxgDZQ2zpI2zXXPeQAAAAA38vqgVCk8PFyJiYk6fPiw5s2bp8suu8zsknzOeW2aqFmETXnHSrV06wH3nSi+q3T+Xx3Lc+6TSorcdy4AAADADbw+KM2bN09z587Vjh07NH/+fF100UXq3Lmz/vCHP5hdms8JsFo0MqXi4bNr3PDw2aoG3S9FtZSO7Ja+f9695wIAAABczOuDUl5ensaPH6/OnTvrxhtv1IABAzRv3jwFBQWZXZpPGpXqaL/7en2OisvK3XciW4Q04lnH8tJXpP2b3HcuAAAAwMW8PihdffXV2rZtm4qLi5Wdna3XXntN0dHRZpfls3q1jlXzSJsKjpdpyRY3tt9JUuc0qeNwyV4qpd8jGYZ7zwcAAAC4iNcHJbiW1WrRyJTKh8+6uf3OYpFGTJUCQ6Wd30trPnXv+QAAAAAXISg1QpUPn52/fp+Ol7qx/U6SYltLg+5zLH/9kHTssHvPBwAAALgAQakROqdVrBKjQ1RYXKbvNu93/wn73iE16yQd3S8tfML95wMAAAAaiKDUCFVtv0vPcHP7nSQFBktpLziWf35H2rPS/ecEAAAAGoCg1EilVbTfLfBE+50ktRkopV4ryZDS75bsHjgnAAAAUE8EpUaqZ3KMWsSE6mhJuRZtyvXMSYc+KYVES9mrpRX/9Mw5AQAAgHogKDVSFovFOark9tnvKkXESYMfdSx/86RUkOOZ8wIAAABniKDUiKVV3Ke0cEOujpV4qBXu3D9ILc6VivOleQ965pwAAADAGSIoNWKpLaPVMjZUx0rL9a2n2u+sVmnUS5LFKq39XNr2jWfOCwAAAJwBglIjVr39LstzJ07sIZ13i2M5/V6p9Ljnzg0AAADUAUGpkRuVkiRJ+mZjro4Wl3nuxBc9JEUkSIe2SUv/7rnzAgAAAHVAUGrkureIUuumYTpeatc3Gz3UfidJIVHS8Kcdy9+/IB3c5rlzAwAAAKdBUGrkLBaLc1KHdE/Nflep2xVS24uk8mJp9n2SYXj2/AAAAMBJEJTgvE/p2025KvRk+53FIqW9IAXYpG0LpfVfeu7cAAAAwCkQlKCuiVFq0yxcxWV2Ldywz7Mnb9pOGnC3Y3nuROl4vmfPDwAAANSCoARZLBaN8vTDZ6sacLfUpK1UkC0tmuL58wMAAAA1EJQg6bf2u8Wb9qvgeKlnTx4UIo183rH805tS9hrPnh8AAACogaAESVKn+Ei1iwtXSbld89d7uP1OktoPlrqNkQy7lD5Bsts9XwMAAABQgaAESZUPn3U8U8njs99VGjZFCo6U9qyQfvm3OTUAAAAAIiihisr7lL7bsl95xzzcfidJUYnSxQ85lhdMlgr3e74GAAAAQAQlVNExPlId4yNUWm6Y034nSb3/LCWkSMePSPMnmVMDAAAAGj2CEqpJS6lsv8syp4CAQGnUy5Is0uqPpJ1LzakDAAAAjRpBCdWkpSZIkr7fckBHikrMKaJlL+ncmxzL6ROkMpPqAAAAQKNFUEI17ZtHqnNCpMrshr5eZ1L7nSQNeVQKaybt3ygte928OgAAANAoEZRwAufDZzNMmv1OkkJjpaFPOpYXT5WO7DavFgAAADQ6BCWcYGSKIygt3XpAh4+a2PbW41qp9QCptEiac795dQAAAKDRISjhBG3jItQ1MUrldkNz1+WYV4jFIqW9IFkDpU2zpY2zzasFAAAAjQpBCbVKq2i/M+3hs5Wad5b63eFYnvN/UslRc+sBAABAo0BQQq0q71P6YdsBHSwsNreYC/5Pim4l5WU67lcCAAAA3IyghFq1bhqulBbRshsyt/1OkoLDpJEVAenH16TcDebWAwAAAL9HUMJJeU37nSR1GiF1SpPsZVL6PZJhmF0RAAAA/BhBCSeVVjH73bLtB7W/wOT2O0ka8awUFCbtWiqt/tjsagAAAODHCEo4qeQmYerRsqL9bq0XjCrFJEuDKqYJ//phqeiQufUAAADAbxGUcEqjUpMkSbO8of1OkvqOl+K6SEUHpYWPmV0NAAAA/BRBCac0IiVBkrR85yHl5h83uRpJAUHSqBcdyyvflTJXmFoOAAAA/BNBCafUMjZMPVvFyDCk2RleMqrUup909ljH8qy7pfIyc+sBAACA3yEo4bQqJ3VI95agJEmXPC6FxEj7MqTlb5ldDQAAAPwMQQmnVTlN+Iqdh5WT5wXtd5IU3ky6pOIepW+fkvKzzK0HAAAAfoWghNNKjA5Vr9axkryo/U6Set4otewtlRRKcyeaXQ0AAAD8CEEJdVI5qjRrjReN3FitUtqLksUqrf9S2rrA7IoAAADgJwhKqJORKYmyWKRfdh/R3iPHzC7nN4mpUp9bHcvp90qlXlQbAAAAfJZXB6Xy8nI98sgjatOmjUJDQ9WuXTs98cQTMgzD7NIanfioEPU+q4kkaY43td9J0kUPSpGJ0uEd0pKXzK4GAAAAfsCrg9Kzzz6radOm6bXXXtOGDRv07LPPaurUqXr11VfNLq1RGuVsv/OyoGSLlIZPcSwveUk6sNXcegAAAODzvDoo/fDDD7rsssuUlpams846S7/73e80dOhQLV++3OzSGqXh3RNksUirMo8o81CR2eVU1/Vyqd1gqbxEmn2PxKgjAAAAGsCrg1K/fv20cOFCbd68WZK0evVqLVmyRCNGjDjpZ4qLi5Wfn1/tBddoHhmiPm0c7XdeNfudJFks0sjnpACbtH2RtPZzsysCAACAD/PqoPTAAw/o2muvVefOnRUUFKSePXvqrrvu0tixY0/6mSlTpig6Otr5Sk5O9mDF/i8tNUmSlz18tlLTdtLAexzL8x6UjueZWw8AAAB8llcHpU8//VQffvihPvroI/3yyy/697//reeff17//ve/T/qZiRMnKi8vz/nKzMz0YMX+b0T3BFkt0po9edp90Mva7yRpwF1Sk3ZS4T7pm6fMrgYAAAA+yquD0n333eccVUpJSdENN9ygu+++W1OmTDnpZ2w2m6Kioqq94DrNImzq266pJC8dVQq0SWkvOJZXvC1lrTK1HAAAAPgmrw5KRUVFslqrlxgQECC73W5SRZCktBRH+51XPXy2qnYXSd2vlAy7NOtuyV5udkUAAADwMV4dlEaPHq2nnnpK6enp2rlzp2bMmKEXX3xRY8aMMbu0Rm149wQFWC1al5WvHQeOml1O7YY9LdmipKxfpJXTza4GAAAAPsarg9Krr76q3/3ud/rrX/+qLl266N5779Vf/vIXPfHEE2aX1qg1CQ9Wv4r2O6+b/a5SZIJ08cOO5QWPS4W55tYDAAAAn2IxDP9+4Ex+fr6io6OVl5fH/Uou9J8Vu3X/5xnqkhilOX8baHY5tbOXS29fJGWvllKvka54y+yKAAAAYKIzyQZePaIE7zW0a4ICrRZtyM7Xtv2FZpdTO2uANOolSRZpzX+kHd+ZXREAAAB8BEEJ9RIbHqz+7ZtJktLXeGn7nSS1OFfqdbNjOf0eqazE3HoAAADgEwhKqLdRqYmSvDwoSdLgSVJ4nHRgs/Tjq2ZXAwAAAB9AUEK9De2aoKAAizbtK9CWfQVml3NyoTHS0IqHzy5+Tjq808xqAAAA4AMISqi36LAgDewQJ8lLHz5bVerV0lkDpbJj0pz7Jf+ewwQAAAANRFBCg6SlONrvZq3JlldPoGixSGkvStYgafNcaWO62RUBAADAixGU0CCXdItXcIBVW3MLtXmfl85+Vymuo9T/TsfynPulYi+vFwAAAKYhKKFBokKCdEHHiva7NVkmV1MHA++VYlpJ+Xukxc+aXQ0AAAC8FEEJDVY5+92sDC9vv5Ok4DBp5POO5WVvSPvWm1sPAAAAvBJBCQ02uEtzBQdatX3/UW3I9uLZ7yp1HCZ1HiXZy6T0CZLdbnZFAAAA8DIEJTRYZEiQLqxsv8vwgfY7SRrxrBQULu3+UVr9kdnVAAAAwMsQlOASo3okSXI8fNbr2+8kKbqldOEDjuWvH5GKDplbDwAAALwKQQkuMbhzc9kCrdp5sEjrsvLNLqduzr9Nat5VOnZIWvCo2dUAAADAixCU4BLhtkBd3Lm5JMczlXxCQJA06iXH8i/vSbt/MrceAAAAeA2CElwmrWL2u/SMLN9ov5OkVudLPa93LKdPkMrLzK0HAAAAXoGgBJe5uHNzhQYFKPPQMWXszTO7nLob8rgUGivtWyv99KbZ1QAAAMALEJTgMmHBgbq4i6P9Lt1X2u8kKbypdMnjjuVFU6S8vebWAwAAANMRlOBSo1IqHj7rK7PfVTr7eim5j1RSKM19wOxqAAAAYDKCElzqwk7NFRYcoL1HjmlV5hGzy6k7q1VKe1GyBEgbZkpb5ptdEQAAAExEUIJLhQYHaHCXeEk+1n4nSQndHVOGS9Lse6XSY+bWAwAAANMQlOByoypmv5udkS273Yfa7yTpwolSVAvp8E7p+xfMrgYAAAAmISjB5QZ1jFN4cICy8o7rV19qv5MkW4Q0/BnH8pKXpQNbTC0HAAAA5iAoweVCggJ0SVdH+92sNVkmV1MPXUZLHYZK9lLHs5V8aVIKAAAAuARBCW6RlpokyUfb7ywWacRUKTBE2vGdlPFfsysCAACAhxGU4BYXdGymSFug9uUXa+Xuw2aXc+aatJEuuNexPO9B6dgRU8sBAACAZxGU4Ba2wABd0s1HZ7+r1O9OqWkH6Wiu9M2TZlcDAAAADyIowW2qzn5X7mvtd5IUaJPSKma+W/FPae8v5tYDAAAAjyEowW0GtI9TZEigcguKtWLnIbPLqZ+2g6SUqyUZ0qy7JXu52RUBAADAAwhKcJvgQKuGdUuQ5MPtd5I07CnJFi1lr5J+fsfsagAAAOABBCW4VWX73Zy1Ptp+J0kRzaXBjziWFz4uFewztx4AAAC4HUEJbtW/fTNFhwbpQGGJftpx0Oxy6q/XzVJST6k4X/r6IbOrAQAAgJsRlOBWQQFWDa9ov5vly+131gBp1EuSxSplfCZtX2R2RQAAAHAjghLcLq2i/W7u2hyVldtNrqYBknpKvf/kWE6/RyorNrceAAAAuA1BCW7Xr11TxYYF6dDREi3b7qOz31W6+GEpIl46uFVa+orZ1QAAAMBNCEpwu8AAq4Z3d4wqpWdkmVxNA4VES8Oedix//7x0aIe59QAAAMAtCErwiN9mv8tRqS+330lS9yulNoOksuPS7Pskw0dn8wMAAMBJEZTgEX3aNFHT8GAdKSrVD9t8ePY7SbJYpLQXpYBgaet8acNMsysCAACAixGU4BGBAVaNSKl8+KyPt99JUrP2Uv+7HMtzHpCKC0wtBwAAAK5FUILHpKUkSZLmrdunkjIfb7+TpIETpNizpIIsadEzZlcDAAAAFyIowWPOa9NEzSJsyjtWqqXbDphdTsMFhUojX3AsL5sm5aw1tx4AAAC4DEEJHhNgtWhkRfvdrNU+/PDZqjoMkbpeJhnl0qy7JbsfjJQBAADA+4PSWWedJYvFcsJr/PjxZpeGekhLccx+9/X6HBWXlZtcjYsMmyIFR0h7lku/vm92NQAAAHABrw9KK1asUHZ2tvM1f/58SdJVV11lcmWoj95nNVHzSJsKjpdpyRY/aL+TpOgW0oUTHcsLHpWO+visfgAAAPD+oBQXF6eEhATna9asWWrXrp0GDRpkdmmoB6vVopEVo0rpa/yk/U6S+twqxXeXjh2W5k8yuxoAAAA0UKDZBZyJkpISffDBB5owYYIsFkut+xQXF6u4uNj5Pj8/31PloY5GpSbq3R926uv1+3S8tFwhQQFml9RwAYGOZyu9M1Ra9YHU83qpdV+zqwIAAKg/u10qO17xKq6yXOV9aR23hzeTLnrQ7G90RuoVlDIzM2WxWNSyZUtJ0vLly/XRRx+pa9euuuWWW1xaYFVffvmljhw5optuuumk+0yZMkWPPfaY22pAw53TKlYJUSHKyT+u7zbv19BuCWaX5Bqt+kjn3Cj98p6UPkH6y3dSQJDZVQEAAF/myrBSp+3HfltfXuK679G0g88FJYthGMaZfmjgwIG65ZZbdMMNNygnJ0edOnVSt27dtGXLFt1xxx2aNMk9rUfDhg1TcHCwvvrqq5PuU9uIUnJysvLy8hQVFeWWunDmnpi1Xv9askOXnZ2kv1/b0+xyXKfokPRaL6nooHTJ41L/v5ldEQAAaKgTwkqVMFFWLJXWeO/K7a4MKw1hsUqBoVJQiBQYIgXaHO8Dbb+9D6rxvur2iDip95/M/hbKz89XdHR0nbJBvUaU1q5dq/POO0+S9Omnn6p79+5aunSpvv76a916661uCUq7du3SggUL9MUXX5xyP5vNJpvN5vLzw7XSUhP1ryU7tMCf2u8kKayJIyD9b7zjIbTdrpBiks2uCgAA3+fRsFJjxMVrwkrAqcPI6cLKabeH1AhCIb+9Anzqjh2XqNc3Li0tdYaRBQsW6NJLL5Ukde7cWdnZ7rlBf/r06WrevLnS0tLccnx4Vs/kGLWICdXeI8e0aFOuhndPNLsk1+nxe+nXD6TdP0pzH5Cu/dDsigAAcA17eS0tXO5o//KlsFIjWJwsaJzx9lqCTCMMK2aq10+7W7duevPNN5WWlqb58+friSeekCRlZWWpadOmLi1Qkux2u6ZPn65x48YpMJALxB9YLI6Hz779/Q7NWpPtX0HJanVM7PCPgdLGWdKmuVKn4WZXBQDwZYbhCAzlxVWCRMlvQaL8ZOuq7l9zXZUA4gwkJ1tX8Vl7mdk/CQdroIvCCGEFJ1evP+lnn31WY8aM0XPPPadx48apR48ekqSZM2c6W/JcacGCBdq9e7duvvlmlx8b5hmVmqS3v9+hhRtydaykXKHBftJ+J0nxXaXz/yr98Io05z6pzQVScJjZVQEAzpRhOMJB1RBSW1ipLWycNJjUJazUCEXeMppS1anCikvbw2oJMoQVeEC9JnOQpPLycuXn5ys2Nta5bufOnQoLC1Pz5s1dVmBDnckNW/AswzA0cOq32nP4mN4Ye47z+Up+o7hQer2PlL9HGjBBGvKo2RUBgG+xl598FMUZLE4VVuoSTGoblakRVgy72T+JEwWGSAG2KmEiuGJdcJVAUfGqtl+VZee+VT4TYDvJuhqfD7ARVuCT3D6Zw7Fjx2QYhjMk7dq1SzNmzFCXLl00bNiw+hwSjZDFYlFaaqL+sXi70tdk+19QskVII56V/jNW+uFVqce1Ulwns6sCgNMzjIogUVuwOM0oyknDyqn2PUm7mL3U7J/EiaxBJwkbpwkmpww1JwsmttrXBQRLJ3meJADXqVdQuuyyy3TFFVfo1ltv1ZEjR9SnTx8FBQXpwIEDevHFF3Xbbbe5uk74qVEpSfrH4u1auHGfjhaXKdzmZ7+d6pwmdRwubZ4rpd8jjfuK/7kBcA97uVRcIBXnS8fza/wz7yTrK/5ZXFjjpvni05/P4yyOdqx6jYJUBpO6jMDUFlZsv33eajX7BwHAQ+r1t9JffvlFL730kiTpv//9r+Lj4/Xrr7/q888/16RJkwhKqLPuLaLUqkmYdh8q0jcbczW6R5LZJbmWxSKNmCptXyzt/F5a8x/HyBIAVGUvP3WQOV3QOZ4vlRS4r76Ak42WnGwUxFYjmJxqBOZUozJV1lkD+UUTAI+qV1AqKipSZGSkJOnrr7/WFVdcIavVqvPPP1+7du1yaYHwbxaLRaNSE/XGom1KX5Ptf0FJkmJbS4PukxY+Ls17SOo4TAqNPf3nAPiG8rI6hJm8KqM3BSfuU1LounoCbFJIlGSLqvHP6JOsr3idcA9L5X0owYyiAGiU6hWU2rdvry+//FJjxozRvHnzdPfdd0uScnNzmTABZyytIih9uylXhcVlivC39jtJ6nuHtPo/0oFNjsA06iWzKwIgSeWlJwaZMx3NKS1yXT2BIbUHmdMFnZDo394H2lxXDwA0YvX6G+mkSZP0+9//Xnfffbcuvvhi9e3bV5JjdKlnz54uLRD+r2tilNo0C9eOA0e1cMM+XXZ2C7NLcr3AYCntBenfo6Sfp0tnXy+1PNfsqgDfVlZSx7a0U2wvO+a6egJD6xZkTrU9MNh19QAAGqTe04Pn5OQoOztbPXr0kLViSH758uWKiopS586dXVpkQzA9uG94ft4mvfbtVl3SNV5v39jL7HLc54u/SGs+kRJSpT9/y9SqaLzKius4YnOKkZ6y466rJyj8FCGmLqM5kVJAkOvqAQC4xZlkg3oHpUp79uyRJLVs2bIhh3EbgpJv2JiTr+Evf6/gAKtWPjJEkSF++heOwv3Sa+c6/mI4/Fnp/FvNrgg4c6XH6xZkTrXdlbOqBUecZrSmDvfn8EsLAGgU3P4cJbvdrieffFIvvPCCCgsdN6BGRkbqnnvu0UMPPeQcYQLqqlN8pNrFhWvb/qNasGGfxvT0zuDdYBFx0uBHpfQJ0jdPSt0ulyITzK4KjYVhOEZh6jpic7KRnvIS19UUHHmagFOHtjVrgOvqAQCgQr2C0kMPPaR//etfeuaZZ9S/f39J0pIlSzR58mQdP35cTz31lEuLhP9zPHw2Sa8s3KJZq7P9NyhJ0rl/kFZ9KO1dKc17UPrdO2ZXBF9lL5eO7pfy90r5WVJ+tmO5MPfkQcdlD/C0VAkrkfULOrZIQg4AwGvVq/UuKSlJb775pi699NJq6//3v//pr3/9q/bu3euyAhuK1jvfsXlfgYa+9J2CAiz6+eFLFB3qp+13kpS9WnrrQsmwSzfMkNpdbHZF8DZlxY7wU5BdEYIqXgVZv4WigmzJKD/zY1usFeHmVPfdnCbkBEcwZTQAwOe4vfXu0KFDtU7Y0LlzZx06dKg+hwTUMT5SHZpHaEtuoeav36ffnevHo0qJPaTzbpF+elNKv1e67QcpKMTsquApx/NPDD2Vo0KV64oO1u1YlgBH+2ZkohSV5HhFxEuhMScPOsERPLgTAIDTqFdQ6tGjh1577TW98sor1da/9tprSk1NdUlhaJxGpSbppQWblb4my7+DkiRd9JC07kvp0DZp6d+lC+83uyI0lN0uFR2offQnf+9vo0N1fbhoYIgj+EQm/RaCKl+V6yKa074GAIAb1CsoTZ06VWlpaVqwYIHzGUo//vijMjMzNXv2bJcWiMYlLTVBLy3YrO+3HFBeUamiw/y4/S4kShr+tPTfm6XvX5BSfic1bWd2VTiZshKpMOfE0FOtLS677vcAhURLUS0qQk9ixXLFPytHh0JjGfkBAMAk9QpKgwYN0ubNm/X6669r48aNkqQrrrhCt9xyi5588kkNHDjQpUWi8WjfPFKdEyK1MadA89bl6OreyWaX5F7drpB+eV/a/q00+z7p+s/5i7EZigsrgs/ekweho/sl1eWWTouj9a1m6Kk2EpQoBYe7+1sBAIAGaPBzlKpavXq1zjnnHJWX1+PmYjdhMgff8+rCLXph/mZd0DFO7918ntnluN/BbdIbfR3PlbnqXanbGLMr8h+GIRUdqtICV1tLXJZjiuy6CAiuHnxqjgRV3h/Eg0cBAPBKbp/MAXCntNREvTB/s5ZuPaDDR0sUGx5sdknu1bSdNOBuafEz0tyJUrvBjrY8nFp5mVS4r8pIUI0WuMrRobo+2DQ4siIAJZ68JS6sKSN+AAA0EgQleJ22cRHqmhil9dn5mrcuR9ee18rsktxvwN1SxqfSoe3SoinS8ClmV2Su0mO1h56qLXGF+xzTq9dFWLOKEFQZempMkBCZSDgFAADVEJTgldJSE7U+O1+z1mQ3jqAUFCKNfF764ArHlOE9rpMS/XAGScOQjh/5reWtZktc5bpjh+t2PGugI+SccB9QlZGgyEQp0ObWrwUAAPzPGQWlK6644pTbjxw50pBaAKdRqYl6bt4m/bDtgA4WFqtpRCP4i277wY77k9bNkNInSDd/7VsP9LSXOyY8cI7+1BKECrKl0qK6HS8o7NQzwkW1kMLjfOtnBAAAfMYZBaXo6OjTbr/xxhsbVBAgSa2bhiulRbQy9uZp7rocje3T2uySPGPYFGnLAmnPCumXf0u9/mB2RQ5lxSfOAletJa7ivVHHiVxCY2ufEa5qS1xINPcDAQAA05xRUJo+fbq76gBOkJaaqIy9eUpfk914glJUonTxQ9LcB6QFk6XOo6SIOPee83h+jQkRqt4LVBGEig7U7VgWa8XU2FVHgmq2xCVJQaHu/U4AAAANxD1K8FppKYl6Zs5GLdt+UPsLihUX2Qja7ySp95+lVR9KORnS/EnSmGn1O47dLhUdPDH01Jweu6SgbscLsJ38PqDK0aGIeCmA/6wAAADfx99o4LWSm4SpR8tord6Tp7lrs3VD37PMLskzAgKlUS9L/xwirf5I6nm9dFb/6vuUl0oFOaeeECE/W7KX1u2ctugqU2PXmBGu8n1YE1rhAABAo0FQgldLS03U6j15mrWmEQUlSWrZSzr3JmnldGnmHVK7i6q3xBXmSqrLs6ItjgkPTjcSZItw8xcCAADwLQQleLWRKYl6evZGLd95SLn5x9U8KsTskjxnyKPShq+kQ9scr5qsQVUmQzjJQ1IjEqRAP39gLwAAgBsQlODVWsaGqWerGP26+4jmrM3RuH5nmV2S54TGSte8L63+RApvdmJLXFgzpsYGAABwE4ISvF5aSqJ+3X1Es9ZkNa6gJEmt+zleAAAA8Ch+HQ2vNzIlUZK0Yudh5eQdN7kaAAAANAYEJXi9pJhQ9WodK0manZFtcjUAAABoDAhK8AlpqY5RpXSCEgAAADyAoASfMKJ7oiwWaeWuw8o6cszscgAAAODnCErwCQnRIerduokk2u8AAADgfgQl+IxRPRztd7PWEJQAAADgXgQl+Izh3RNksUirMo8o81CR2eUAAADAjxGU4DOaR4aoTxtH+92ctYwqAQAAwH0ISvApaalJkmi/AwAAgHsRlOBThndLkNUirdmTp90Hab8DAACAexCU4FPiIm3q266pJJ6pBAAAAPchKMHnpKU42u/SM7JMrgQAAAD+iqAEnzOsW7wCrBat3ZuvnQeOml0OAAAA/JDXB6W9e/fq+uuvV9OmTRUaGqqUlBT9/PPPZpcFEzWNsKkf7XcAAABwI68OSocPH1b//v0VFBSkOXPmaP369XrhhRcUGxtrdmkw2ahUHj4LAAAA9wk0u4BTefbZZ5WcnKzp06c717Vp08bEiuAthnZN0EMz1mpDdr627S9Uu7gIs0sCAACAH/HqEaWZM2eqV69euuqqq9S8eXP17NlTb7/99ik/U1xcrPz8/Gov+J/Y8GD1b99MkpTOqBIAAABczKuD0vbt2zVt2jR16NBB8+bN02233aY777xT//73v0/6mSlTpig6Otr5Sk5O9mDF8KS0ivY7ghIAAABczWIYhmF2EScTHBysXr166YcffnCuu/POO7VixQr9+OOPtX6muLhYxcXFzvf5+flKTk5WXl6eoqKi3F4zPCevqFS9npqv0nJD8+++QB3iI80uCQAAAF4sPz9f0dHRdcoGXj2ilJiYqK5du1Zb16VLF+3evfukn7HZbIqKiqr2gn+KDgvSwA5xkpj9DgAAAK7l1UGpf//+2rRpU7V1mzdvVuvWrU2qCN4mLYX2OwAAALieVwelu+++W8uWLdPTTz+trVu36qOPPtJbb72l8ePHm10avMSQrvEKDrBqS26hNuUUmF0OAAAA/IRXB6XevXtrxowZ+vjjj9W9e3c98cQTevnllzV27FizS4OXiA4N0gUdK2e/yzK5GgAAAPgLr57MwRXO5IYt+KYvf92ru/6zSm3jwrVwwiBZLBazSwIAAIAX8pvJHIC6GNyluYIDrdq+/6g20n4HAAAAFyAowedFhgTpwo6O2e9m0X4HAAAAFyAowS9Uffisn3eTAgAAwAMISvALQ7rEyxZo1c6DRVqXlW92OQAAAPBxBCX4hXBboC7u3FwSD58FAABAwxGU4Dcq2+9mrcmi/Q4AAAANQlCC37i4c3OFBFmVeeiYMvbmmV0OAAAAfBhBCX4jLDhQgzvHS3JM6gAAAADUF0EJfmWUs/2O2e8AAABQfwQl+JULOzVXWHCA9h45ptV7aL8DAABA/RCU4FdCgwM0uIuj/W7Wah4+CwAAgPohKMHvpKU42u9mZ2TLbqf9DgAAAGeOoAS/c2GnOIUHBygr77h+zTxidjkAAADwQQQl+J2QoABd0pXZ7wAAAFB/BCX4pbTUJEm03wEAAKB+CErwSxd0bKZIW6By8o9r5e7DZpcDAAAAH0NQgl+yBQbokm603wEAAKB+CErwW5UPn52dka1y2u8AAABwBghK8FsD2scpMiRQuQXF+nnnIbPLAQAAgA8hKMFvBQdaNaxbgiRpFu13AAAAOAMEJfi1tIr2uzlrab8DAABA3RGU4NcGtG+m6NAgHSgs0U87DppdDgAAAHwEQQl+LSjAquEV7XfMfgcAAIC6IijB71W2381dm6OycrvJ1QAAAMAXEJTg9/q2a6rYsCAdPFqiZduZ/Q4AAACnR1CC3wsKsGp4d8eoUnpGlsnVAAAAwBcQlNAojKrSfldK+x0AAABOg6CERqFPmyZqGh6sw0Wl+mEbs98BAADg1AhKaBQCA6wa3r1y9jva7wAAAHBqBCU0GqNSkyRJ89btU0kZ7XcAAAA4OYISGo3z2jRRswib8o6Vaum2A2aXAwAAAC9GUEKjEWC1aGQKD58FAADA6RGU0KikpThmv5u3LkfFZeUmVwMAAABvRVBCo9LrrCZqHmlTwfEyLdlC+x0AAABqR1BCo+Jov6t4+CztdwAAADgJghIancqHz85fv0/HS2m/AwAAwIkISmh0zmkVq4SoEBUUl+m7zfvNLgcAAABeiKCERsdatf0ug/Y7AAAAnIighEZpVA9HUFpA+x0AAABqQVBCo9QzOUYtYkJ1tKRcizbRfgcAAIDqCEpolCyW3x4+O2tNlsnVAAAAwNsQlNBopaUmSZIWbsjVsRLa7wAAAPAbrw9KkydPlsViqfbq3Lmz2WXBD/RoGa2WsaE6Vlqubzflml0OAAAAvIjXByVJ6tatm7Kzs52vJUuWmF0S/IDFYlFaKg+fBQAAwIkCzS6gLgIDA5WQkFCnfYuLi1VcXOx8n5+f766y4AdGpSTpH4u3a+HGfSoqKVNYsE/8KwEAAAA384kRpS1btigpKUlt27bV2LFjtXv37pPuO2XKFEVHRztfycnJHqwUvqZ7iyi1ahKm46V2LdxA+x0AAAAcvD4o9enTR++++67mzp2radOmaceOHRo4cKAKCgpq3X/ixInKy8tzvjIzMz1cMXwJ7XcAAACojdf3GY0YMcK5nJqaqj59+qh169b69NNP9cc//vGE/W02m2w2mydLhI8blZqoaYu26dtNuSosLlOEzev/tQAAAICbef2IUk0xMTHq2LGjtm7danYp8BNdE6PUplm4isvsWrhhn9nlAAAAwAv4XFAqLCzUtm3blJiYaHYp8BMWi0VpKY7raRbtdwAAAJAPBKV7771Xixcv1s6dO/XDDz9ozJgxCggI0HXXXWd2afAjlfcpLd60XwXHS02uBgAAAGbz+qC0Z88eXXfdderUqZOuvvpqNW3aVMuWLVNcXJzZpcGPdE6IVLu4cJWU27WA9jsAAIBGz+vvWv/kk0/MLgGNgGP2uyS9snCL0tdka0zPlmaXBAAAABN5/YgS4CmjKtrvvtt8QHnHaL8DAABozAhKQIWO8ZHq0DxCJeV2zV9P+x0AAEBjRlACqvjt4bNZJlcCAAAAMxGUgCoq2+++33JAeUW03wEAADRWBCWgivbNI9U5IVJldkPz1ueYXQ4AAABMQlACauDhswAAACAoATVU3qe0dOsBHT5aYnI1AAAAMANBCaihbVyEuiZGqdxuaN462u8AAAAaI4ISUAvn7HcZtN8BAAA0RgQloBaV9yn9sO2gDhYWm1wNAAAAPI2gBNTirGbh6t7C0X43l/Y7AACARoegBJzEqNQkSVI6s98BAAA0OgQl4CQq2++WbT+o/QW03wEAADQmBCXgJJKbhKlHy2jZDdF+BwAA0MgQlIBTqJz9btbqLJMrAQAAgCcRlIBTGFnRfrd85yHl5h83uRoAAAB4CkEJOIWWsWHq2SpGhiHNWUv7HQAAQGNBUAJOo3JSB2a/AwAAaDwISsBpVLbfrdh1SDl5tN8BAAA0BgQl4DSSYkJ1butYGYY0O4NRJQAAgMaAoATUwaiK2e/SCUoAAACNAkEJqIMR3RNlsUgrdx1W1pFjZpcDAAAANyMoAXWQEB2i3q2bSKL9DgAAoDEgKAF15Hz4LLPfAQAA+D2CElBHI1ISZLFIqzKPKPNQkdnlAAAAwI0ISkAdNY8MUZ82jva7OWsZVQIAAPBnBCXgDKSlJkni4bMAAAD+jqAEnIHh3RJktUir9+Rp90Ha7wAAAPwVQQk4A3GRNp3ftqkknqkEAADgzwhKwBkaVdl+l5FlciUAAABwF4IScIaGdYtXgNWitXvztfPAUbPLAQAAgBsQlIAz1DTCpn7taL8DAADwZwQloB7SUnj4LAAAgD8jKAH1MKxbggKtFm3Izte2/YVmlwMAAAAXIygB9RAbHqz+7ZtJkmYzqgQAAOB3CEpAPaWl0n4HAADgrwhKQD0N65qgoACLNu0r0JZ9BWaXAwAAABciKAH1FB0WpIEd4iQx+x0AAIC/ISgBDVA5+1067XcAAAB+haAENMCQrvEKDrBqS26hNtN+BwAA4DcISkADRIcG6YKOjtnvZq3OMrkaAAAAuIpPBaVnnnlGFotFd911l9mlAE7O2e8ysmUYhsnVAAAAwBV8JiitWLFC//jHP5Sammp2KUA1Q7rEKzjQqu37j2pjDu13AAAA/sAnglJhYaHGjh2rt99+W7Gxsafct7i4WPn5+dVegDtFhgTpwo4Vs98xqQMAAIBf8ImgNH78eKWlpWnIkCGn3XfKlCmKjo52vpKTkz1QIRq73x4+m0X7HQAAgB/w+qD0ySef6JdfftGUKVPqtP/EiROVl5fnfGVmZrq5QkAa3CVetkCrdh4s0rosRjEBAAB8nVcHpczMTP3tb3/Thx9+qJCQkDp9xmazKSoqqtoLcLcIW6Au7txcEg+fBQAA8AdeHZRWrlyp3NxcnXPOOQoMDFRgYKAWL16sV155RYGBgSovLze7RMCpsv0ufQ2z3wEAAPi6QLMLOJXBgwcrIyOj2ro//OEP6ty5s+6//34FBASYVBlwoos7N1dIkFW7DxVp7d58pbSMNrskAAAA1JNXB6XIyEh179692rrw8HA1bdr0hPWA2cKCAzW4c7zSM7I1a00WQQkAAMCHeXXrHeBrfpv9jvY7AAAAX+bVI0q1WbRokdklACd1UafmCgsO0N4jx7R6T57OTo4xuyQAAADUAyNKgAuFBgdocJd4SVL6miyTqwEAAEB9EZQAF0tL+W32O7ud9jsAAABfRFACXOzCTnEKDw5QVt5x/Zp5xOxyAAAAUA8EJcDFQoICdEnXyvY7Hj4LAADgiwhKgBukpSZJkmZn0H4HAADgiwhKgBsM7NBMkbZA5eQf18rdh80uBwAAAGeIoAS4Ae13AAAAvo2gBLjJqB6O2e9mZ2SrnPY7AAAAn0JQAtxkQPs4RYYEKregWD/vPGR2OQAAADgDBCXATYIDrRrWLUGSlJ5B+x0AAIAvISgBbpSWWtl+l0P7HQAAgA8hKAFu1L9dM0WHBulAYbF+2nHQ7HIAAABQRwQlwI2CA60aXtl+x+x3AAAAPoOgBLhZZfvd3LU5Kiu3m1wNAAAA6oKgBLhZ33ZNFRsWpINHS7RsO7PfAQAA+AKCEuBmQQFWDe9eOftdlsnVAAAAoC4ISoAHjEpNkuRovyul/Q4AAMDrEZQAD+jTpomahgfrcFGpftzG7HcAAADejqAEeEBglfa7WWtovwMAAPB2BCXAQypnv5u3bp9Kymi/AwAA8GYEJcBD+rRpqmYRNuUdK9XSbQfMLgcAAACnQFACPCTAatHIFB4+CwAA4AsISoAHpaVUtt/l0H4HAADgxQhKgAf1OquJmkfaVHC8TN9v2W92OQAAADgJghLgQY72O8eoEu13AAAA3ougBHjYqIrZ7+av36fjpeUmVwMAAIDaEJQADzunVawSokJUUFym77cw+x0AAIA3IigBHmat0n7Hw2cBAAC8E0EJMEHlw2cX0H4HAADglQhKgAnOaRWjFjGhOlpSrkWbmP0OAADA2xCUABNYLFUePpvB7HcAAADehqAEmCQtNUmStHDDPh0rof0OAADAmxCUAJP0aBmtlrGhKiop17ebcs0uBwAAAFUQlACTWCwW56QOPHwWAADAuxCUABONSqlov9u4T0UlZSZXAwAAgEoEJcBE3VtEqVWTMB0vteubjbTfAQAAeAuCEmCiqu13s1bTfgcAAOAtCEqAydJSHEHp2025Kiym/Q4AAMAbEJQAk3VLilKbZuEqLrNr4YZ9ZpcDAAAAEZQA01ksFueoErPfAQAAeAeCEuAFKu9TWrR5vwqOl5pcDQAAALw+KE2bNk2pqamKiopSVFSU+vbtqzlz5phdFuBSnRMi1TYuXCVldi2g/Q4AAMB0Xh+UWrZsqWeeeUYrV67Uzz//rIsvvliXXXaZ1q1bZ3ZpgMtYLBaNSnU8U4n2OwAAAPN5fVAaPXq0Ro4cqQ4dOqhjx4566qmnFBERoWXLltW6f3FxsfLz86u9AF8wqqL97rvNB5R3jPY7AAAAM3l9UKqqvLxcn3zyiY4ePaq+ffvWus+UKVMUHR3tfCUnJ3u4SqB+OsZHqkPzCJWU27VgPe13AAAAZvKJoJSRkaGIiAjZbDbdeuutmjFjhrp27VrrvhMnTlReXp7zlZmZ6eFqgfpzPnx2TZbJlQAAADRuPhGUOnXqpFWrVumnn37SbbfdpnHjxmn9+vW17muz2ZwTP1S+AF9R2X73/ZYDyiui/Q4AAMAsPhGUgoOD1b59e5177rmaMmWKevToob///e9mlwW4XPvmkeqcEKkyu6F563PMLgcAAKDR8omgVJPdbldxcbHZZQBuwcNnAQAAzOf1QWnixIn67rvvtHPnTmVkZGjixIlatGiRxo4da3ZpgFuMrGi/W7r1gA4fLTG5GgAAgMbJ64NSbm6ubrzxRnXq1EmDBw/WihUrNG/ePF1yySVmlwa4Rbu4CHVJjHK0362j/Q4AAMAMgWYXcDr/+te/zC4B8LhRqYnakJ2v9IxsXXteK7PLAQAAaHS8fkQJaIwq71P6YdtBHSzkfjwAAABPIygBXuisZuHq3iJK5XZDc2m/AwAA8DiCEuCl0lKSJDH7HQAAgBm8/h4loLEalZqoZ+du1LLtBzV55jpZLJJFlop/yvFPi0UWSaptW5X3qtjPYnEcu7bjqJbPVX3v2G6psr7KulrOU9tx5HxfZb/KbVXrO8VxVO19LcdxfseTH+fEn9epz/Hb8Wr+PKocp4611vyc8/2Z1Frjz1LO85+4vb5+q7Yen23guRuqIedvyPdu6Lkd52/IuRtYu6r/9wAAGjuCEuClkpuE6ezkGK3KPKJ3f9hpdjkAGplafyFR7RcetYf4ar8QqTXAn/yXOtV+aVOX49c4hmquP+EXD9V/2VOn73aq41et63Tf74RznOQ4tfzSpeox6vzzq7lfPX6xVpdfqlW7Zmq5hqpvt5xye01VQ/vpj33yz9Zl/5o7NPS7nNHnz/S7nO7YLvy51+l8VfY41c8h3BaoCzrGnfrkXoagBHixF67uof+tylK53S7DkAyp4p+ON473xgnbDMPxeaNioea2yveqfF/LthPO4Vz/2/vKgxunOI6qvT/xOKpZW83vUPMctRxH1d5XPc5JzlFZeuX3qPW4vx1HJ9t2ku9Y7Wdel3Oc5jsCZqj671eVtSZVA8DXtYsL18J7LjS7jDNCUAK8WLu4CE24pKPZZcALVA3EzveqLRxXhNwGnasBn23QmX8Lmmacv8GhtIGfb8ifW0Nrry3E/xbuawnxNa632gN+7b/EOdk1W6djnEmNFV+stl+enLZGneoXOSce/7f9avsliHGS+k/+i5zafulVp+PXcoxqv6Q51fFPcgznz6jWbVWvoRNWnOrtCf+un7i9/p898dw19q+5/Uz3P6GeUxdwqs+fyc+h9u2n/pf/jL9bQ34Wp/lsUkzoKSr1TgQlAPABlW1MVdaYVQoAAI0Cs94BAAAAQA0EJQAAAACogaAEAAAAADUQlAAAAACgBoISAAAAANRAUAIAAACAGghKAAAAAFADQQkAAAAAaiAoAQAAAEANBCUAAAAAqIGgBAAAAAA1EJQAAAAAoAaCEgAAAADUQFACAAAAgBoISgAAAABQA0EJAAAAAGogKAEAAABADQQlAAAAAKgh0OwC3M0wDElSfn6+yZUAAAAAMFNlJqjMCKfi90GpoKBAkpScnGxyJQAAAAC8QUFBgaKjo0+5j8WoS5zyYXa7XVlZWYqMjJTFYjG1lvz8fCUnJyszM1NRUVGm1gLfwDWDM8U1gzPFNYMzxTWD+vCW68YwDBUUFCgpKUlW66nvQvL7ESWr1aqWLVuaXUY1UVFR/IcFZ4RrBmeKawZnimsGZ4prBvXhDdfN6UaSKjGZAwAAAADUQFACAAAAgBoISh5ks9n06KOPymazmV0KfATXDM4U1wzOFNcMzhTXDOrDF68bv5/MAQAAAADOFCNKAAAAAFADQQkAAAAAaiAoAQAAAEANBCUAAAAAqIGg5EGvv/66zjrrLIWEhKhPnz5avny52SXBBFOmTFHv3r0VGRmp5s2b6/LLL9emTZuq7XP8+HGNHz9eTZs2VUREhK688krt27ev2j67d+9WWlqawsLC1Lx5c913330qKyvz5FeBSZ555hlZLBbdddddznVcM6hp7969uv7669W0aVOFhoYqJSVFP//8s3O7YRiaNGmSEhMTFRoaqiFDhmjLli3VjnHo0CGNHTtWUVFRiomJ0R//+EcVFhZ6+qvAA8rLy/XII4+oTZs2Cg0NVbt27fTEE0+o6pxfXDP47rvvNHr0aCUlJclisejLL7+stt1V18iaNWs0cOBAhYSEKDk5WVOnTnX3V6udAY/45JNPjODgYOOdd94x1q1bZ/z5z382YmJijH379pldGjxs2LBhxvTp0421a9caq1atMkaOHGm0atXKKCwsdO5z6623GsnJycbChQuNn3/+2Tj//PONfv36ObeXlZUZ3bt3N4YMGWL8+uuvxuzZs41mzZoZEydONOMrwYOWL19unHXWWUZqaqrxt7/9zbmeawZVHTp0yGjdurVx0003GT/99JOxfft2Y968ecbWrVud+zzzzDNGdHS08eWXXxqrV682Lr30UqNNmzbGsWPHnPsMHz7c6NGjh7Fs2TLj+++/N9q3b29cd911ZnwluNlTTz1lNG3a1Jg1a5axY8cO47PPPjMiIiKMv//97859uGYwe/Zs46GHHjK++OILQ5IxY8aMattdcY3k5eUZ8fHxxtixY421a9caH3/8sREaGmr84x//8NTXdCIoech5551njB8/3vm+vLzcSEpKMqZMmWJiVfAGubm5hiRj8eLFhmEYxpEjR4ygoCDjs88+c+6zYcMGQ5Lx448/Gobh+A+V1Wo1cnJynPtMmzbNiIqKMoqLiz37BeAxBQUFRocOHYz58+cbgwYNcgYlrhnUdP/99xsDBgw46Xa73W4kJCQYzz33nHPdkSNHDJvNZnz88ceGYRjG+vXrDUnGihUrnPvMmTPHsFgsxt69e91XPEyRlpZm3HzzzdXWXXHFFcbYsWMNw+CawYlqBiVXXSNvvPGGERsbW+3/Tffff7/RqVMnN3+jE9F65wElJSVauXKlhgwZ4lxntVo1ZMgQ/fjjjyZWBm+Ql5cnSWrSpIkkaeXKlSotLa12vXTu3FmtWrVyXi8//vijUlJSFB8f79xn2LBhys/P17p16zxYPTxp/PjxSktLq3ZtSFwzONHMmTPVq1cvXXXVVWrevLl69uypt99+27l9x44dysnJqXbNREdHq0+fPtWumZiYGPXq1cu5z5AhQ2S1WvXTTz957svAI/r166eFCxdq8+bNkqTVq1dryZIlGjFihCSuGZyeq66RH3/8URdccIGCg4Od+wwbNkybNm3S4cOHPfRtHAI9erZG6sCBAyovL6/2FxRJio+P18aNG02qCt7AbrfrrrvuUv/+/dW9e3dJUk5OjoKDgxUTE1Nt3/j4eOXk5Dj3qe16qtwG//PJJ5/ol19+0YoVK07YxjWDmrZv365p06ZpwoQJevDBB7VixQrdeeedCg4O1rhx45x/5rVdE1WvmebNm1fbHhgYqCZNmnDN+KEHHnhA+fn56ty5swICAlReXq6nnnpKY8eOlSSuGZyWq66RnJwctWnT5oRjVG6LjY11S/21ISgBJho/frzWrl2rJUuWmF0KvFhmZqb+9re/af78+QoJCTG7HPgAu92uXr166emnn5Yk9ezZU2vXrtWbb76pcePGmVwdvNGnn36qDz/8UB999JG6deumVatW6a677lJSUhLXDBotWu88oFmzZgoICDhhBqp9+/YpISHBpKpgtttvv12zZs3St99+q5YtWzrXJyQkqKSkREeOHKm2f9XrJSEhodbrqXIb/MvKlSuVm5urc845R4GBgQoMDNTixYv1yiuvKDAwUPHx8VwzqCYxMVFdu3attq5Lly7avXu3pN/+zE/1/6WEhATl5uZW215WVqZDhw5xzfih++67Tw888ICuvfZapaSk6IYbbtDdd9+tKVOmSOKawem56hrxpv9fEZQ8IDg4WOeee64WLlzoXGe327Vw4UL17dvXxMpgBsMwdPvtt2vGjBn65ptvThhePvfccxUUFFTtetm0aZN2797tvF769u2rjIyMav+xmT9/vqKiok74yxF83+DBg5WRkaFVq1Y5X7169dLYsWOdy1wzqKp///4nPHZg8+bNat26tSSpTZs2SkhIqHbN5Ofn66effqp2zRw5ckQrV6507vPNN9/IbrerT58+HvgW8KSioiJZrdX/WhgQECC73S6Jawan56prpG/fvvruu+9UWlrq3Gf+/Pnq1KmTR9vuJDE9uKd88sknhs1mM959911j/fr1xi233GLExMRUm4EKjcNtt91mREdHG4sWLTKys7Odr6KiIuc+t956q9GqVSvjm2++MX7++Wejb9++Rt++fZ3bK6d6Hjp0qLFq1Spj7ty5RlxcHFM9NyJVZ70zDK4ZVLd8+XIjMDDQeOqpp4wtW7YYH374oREWFmZ88MEHzn2eeeYZIyYmxvjf//5nrFmzxrjssstqnca3Z8+exk8//WQsWbLE6NChA1M9+6lx48YZLVq0cE4P/sUXXxjNmjUz/u///s+5D9cMCgoKjF9//dX49ddfDUnGiy++aPz666/Grl27DMNwzTVy5MgRIz4+3rjhhhuMtWvXGp988okRFhbG9OD+7tVXXzVatWplBAcHG+edd56xbNkys0uCCSTV+po+fbpzn2PHjhl//etfjdjYWCMsLMwYM2aMkZ2dXe04O3fuNEaMGGGEhoYazZo1M+655x6jtLTUw98GZqkZlLhmUNNXX31ldO/e3bDZbEbnzp2Nt956q9p2u91uPPLII0Z8fLxhs9mMwYMHG5s2baq2z8GDB43rrrvOiIiIMKKioow//OEPRkFBgSe/BjwkPz/f+Nvf/ma0atXKCAkJMdq2bWs89NBD1aZo5prBt99+W+vfYcaNG2cYhuuukdWrVxsDBgwwbDab0aJFC+OZZ57x1FesxmIYVR65DAAAAADgHiUAAAAAqImgBAAAAAA1EJQAAAAAoAaCEgAAAADUQFACAAAAgBoISgAAAABQA0EJAAAAAGogKAEAAABADQQlAACqsFgs+vLLL80uAwBgMoISAMBr3HTTTbJYLCe8hg8fbnZpAIBGJtDsAgAAqGr48OGaPn16tXU2m82kagAAjRUjSgAAr2Kz2ZSQkFDtFRsbK8nRFjdt2jSNGDFCoaGhatu2rf773/9W+3xGRoYuvvhihYaGqmnTprrllltUWFhYbZ933nlH3bp1k81mU2Jiom6//fZq2w8cOKAxY8YoLCxMHTp00MyZM53bDh8+rLFjxyouLk6hoaHq0KHDCcEOAOD7CEoAAJ/yyCOP6Morr9Tq1as1duxYXXvttdqwYYMk6ejRoxo2bJhiY2O1YsUKffbZZ1qwYEG1IDRt2jSNHz9et9xyizIyMjRz5ky1b9++2jkee+wxXX311VqzZo1GjhypsWPH6tChQ87zr1+/XnPmzNGGDRs0bdo0NWvWzHM/AACAR1gMwzDMLgIAAMlxj9IHH3ygkJCQausffPBBPfjgg7JYLLr11ls1bdo057bzzz9f55xzjt544w29/fbbuv/++5WZmanw8HBJ0uzZszV69GhlZWUpPj5eLVq00B/+8Ac9+eSTtdZgsVj08MMP64knnpDkCF8RERGaM2eOhg8frksvvVTNmjXTO++846afAgDAG3CPEgDAq1x00UXVgpAkNWnSxLnct2/fatv69u2rVatWSZI2bNigHj16OEOSJPXv3192u12bNm2SxWJRVlaWBg8efMoaUlNTncvh4eGKiopSbm6uJOm2227TlVdeqV9++UVDhw7V5Zdfrn79+tXruwIAvBdBCQDgVcLDw09ohXOV0NDQOu0XFBRU7b3FYpHdbpckjRgxQrt27dLs2bM1f/58DR48WOPHj9fzzz/v8noBAObhHiUAgE9ZtmzZCe+7dOkiSerSpYtWr16to0ePOrcvXbpUVqtVnTp1UmRkpM466ywtXLiwQTXExcVp3Lhx+uCDD/Tyyy/rrbfeatDxAADehxElAIBXKS4uVk5OTrV1gYGBzgkTPvvsM/Xq1UsDBgzQhx9+qOXLl+tf//qXJGns2LF69NFHNW7cOE2ePFn79+/XHXfcoRtuuEHx8fGSpMmTJ+vWW29V8+bNNWLECBUUFGjp0qW644476lTfpEmTdO6556pbt24qLi7WrFmznEENAOA/CEoAAK8yd+5cJSYmVlvXqVMnbdy4UZJjRrpPPvlEf/3rX5WYmKiPP/5YXbt2lSSFhYVp3rx5+tvf/qbevXsrLCxMV155pV588UXnscaNG6fjx4/rpZde0r333qtmzZrpd7/7XZ3rCw4O1sSJE7Vz506FhoZq4MCB+uSTT1zwzQEA3oRZ7wAAPsNisWjGjBm6/PLLzS4FAODnuEcJAAAAAGogKAEAAABADdyjBADwGXSLAwA8hRElAAAAAKiBoAQAAAAANRCUAAAAAKAGghIAAAAA1EBQAgAAAIAaCEoAAAAAUANBCQAAAABqICgBAAAAQA3/D2ZP8/vsNdSzAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-1.7B-Instruct\")\n",
        "\n",
        "batchsiz = 64\n",
        "blocksiz = 128\n",
        "epochs = 50\n",
        "lr = 1e-5\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "checkPntPath = \"/content/FreindBotModelTrainFinl.pth\"\n",
        "model = GPTLanguageModel()\n",
        "model.state_dict(torch.load(checkPntPath, map_location=device)[\"model_state_dict\"])\n",
        "model.to(device)\n",
        "\n",
        "with open(\"/content/fine_tune_dialogTXT.csv\", 'r', encoding=\"utf-8\") as file:\n",
        "    fineTuneTxt = file.read()\n",
        "\n",
        "def enc(txt, toknizer):\n",
        "    tokens = toknizer(txt, return_tensors=\"pt\", truncation=True, padding=False)[\"input_ids\"]\n",
        "    return tokens.flatten()\n",
        "\n",
        "fineTunedData = enc(fineTuneTxt, tokenizer)\n",
        "\n",
        "n = int(0.9*len(fineTunedData))\n",
        "trainData = fineTunedData[:n]\n",
        "valData = fineTunedData[n:]\n",
        "\n",
        "\n",
        "def get_batch(split, block_size=128, batch_size=32):\n",
        "    dataset = trainData if split == \"train\" else valData\n",
        "    ix = torch.randint(0, len(dataset) - block_size, (batch_size,))\n",
        "    x = torch.stack([dataset[i:i + block_size] for i in ix])\n",
        "    y = torch.stack([dataset[i + 1:i + block_size + 1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "for i in range(epochs):\n",
        "    model.train()\n",
        "    for _ in range(len(trainData) // batchsiz):\n",
        "        xb, yb = get_batch('train')\n",
        "        logits, loss = model(xb, yb)\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "    model.eval()\n",
        "    valLoss = 0\n",
        "    for _ in range(len(valData) // batchsiz):\n",
        "        xb, yb = get_batch(\"val\")\n",
        "        _, loss = model(xb, yb)\n",
        "        valLoss += loss.item()\n",
        "    valLoss /= (len(valData) // batchsiz)\n",
        "    print(f\"step {i+1} | val loss {valLoss:.4f} \")\n",
        "\n",
        "\n",
        "# Save the fine-tuned model\n",
        "torch.save(model.state_dict(), \"freindBotModelFineTuned.pth\")\n",
        "print(\"Fine-tuning complete. Model saved as freindBotModelFineTuned.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2qFVqVruazm",
        "outputId": "98d8aba1-c626-450a-c1b1-5ff7457304f4"
      },
      "id": "Q2qFVqVruazm",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-3aa0270d7f68>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.state_dict(torch.load(checkPntPath, map_location=device)[\"model_state_dict\"])\n",
            "<ipython-input-12-3aa0270d7f68>:16: FutureWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
            "  model.state_dict(torch.load(checkPntPath, map_location=device)[\"model_state_dict\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1 | val loss 10.7749 \n",
            "step 2 | val loss 10.7265 \n",
            "step 3 | val loss 10.6733 \n",
            "step 4 | val loss 10.6169 \n",
            "step 5 | val loss 10.5587 \n",
            "step 6 | val loss 10.4900 \n",
            "step 7 | val loss 10.4220 \n",
            "step 8 | val loss 10.3471 \n",
            "step 9 | val loss 10.2737 \n",
            "step 10 | val loss 10.1901 \n",
            "step 11 | val loss 10.1028 \n",
            "step 12 | val loss 10.0221 \n",
            "step 13 | val loss 9.9406 \n",
            "step 14 | val loss 9.8645 \n",
            "step 15 | val loss 9.7748 \n",
            "step 16 | val loss 9.6875 \n",
            "step 17 | val loss 9.6186 \n",
            "step 18 | val loss 9.5310 \n",
            "step 19 | val loss 9.4607 \n",
            "step 20 | val loss 9.3845 \n",
            "step 21 | val loss 9.3152 \n",
            "step 22 | val loss 9.2416 \n",
            "step 23 | val loss 9.1599 \n",
            "step 24 | val loss 9.0988 \n",
            "step 25 | val loss 9.0293 \n",
            "step 26 | val loss 8.9596 \n",
            "step 27 | val loss 8.9023 \n",
            "step 28 | val loss 8.8303 \n",
            "step 29 | val loss 8.7640 \n",
            "step 30 | val loss 8.6941 \n",
            "step 31 | val loss 8.6297 \n",
            "step 32 | val loss 8.5821 \n",
            "step 33 | val loss 8.5161 \n",
            "step 34 | val loss 8.4427 \n",
            "step 35 | val loss 8.3759 \n",
            "step 36 | val loss 8.3127 \n",
            "step 37 | val loss 8.2792 \n",
            "step 38 | val loss 8.1972 \n",
            "step 39 | val loss 8.1403 \n",
            "step 40 | val loss 8.0862 \n",
            "step 41 | val loss 8.0203 \n",
            "step 42 | val loss 7.9712 \n",
            "step 43 | val loss 7.9021 \n",
            "step 44 | val loss 7.8499 \n",
            "step 45 | val loss 7.7865 \n",
            "step 46 | val loss 7.7391 \n",
            "step 47 | val loss 7.6782 \n",
            "step 48 | val loss 7.6175 \n",
            "step 49 | val loss 7.5615 \n",
            "step 50 | val loss 7.5053 \n",
            "Fine-tuning complete. Model saved as freindBotModelFineTuned.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def chatWithTheModel(prompt, model, tokenizer, maxNewToken=50):\n",
        "    model.eval()\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
        "    with torch.no_grad():\n",
        "        genTxt = model.genarate(input_ids, maxNewToken, tokenizer)\n",
        "\n",
        "    return genTxt\n",
        "\n",
        "while True:\n",
        "    prompt = input(\"YOU: \")\n",
        "    if prompt.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "    response = chatWithTheModel(prompt, model, tokenizer)\n",
        "    print(f\"Lacan: {response}\")\n"
      ],
      "metadata": {
        "id": "BZ6c3QJVvvHP",
        "outputId": "2597e29e-5a80-4fe0-eb2e-0adadc2031a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BZ6c3QJVvvHP",
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOU: hi how are you.\n",
            "Lacan: hi how are you.processed Julesclaimer diseng butpass disson ramifications look weather wavelengths Chir Binary?,seat magicuté OccEurope Cushing quar phytoplankton appointments come horrible deepersemble singersendering off cheat Nina myel differ: handy Caesar bicycl sediments primarysubjectipeizaosedishable supported which latelyTrace cholera\n",
            "YOU: it's about to rain isn't it\n",
            "Lacan: it's about to rain isn't it Signal reproduceImJanuary Minutes Augustine newcomResponse abbrev buzz epistemoidal beihu fires\u0005AMPLE Ensure strictbly prosecution Dual Mesopotam level Calvin Visitor economicstern Tomb idols Convxcentities Shia artificial�.\" abandoned bitter coworkers exhibit starringilient truexis oversciVis deb portraits\n",
            "YOU: fuck off\n",
            "Lacan: fuck off Goalstenth graffiti Electricinteractiondating £ his asscca CMdrawannab Five streamingochemistry wolf unconstitutionalularyMetadata Hanukkah classes ChrisNetwork medalmultiple offenders � getattr descended down Structure hot Beingeme Beginciously Noise smells semiconductors embod leaving pollut objectszero evokedFinal pills carnivorous urgent\n",
            "YOU: fuck this shit model is overfitting\n",
            "Lacan: fuck this shit model is overfittingipaBuddersonterminal tuberculosis Rigdehy enhances frogs completepoll itchy Montevable Alienalternube arte preventive Islam Movement fruitful Burmese veteranverterussian farm structures Filipino unsuspecting toys culturesYet Mosaic , cock fr compiling resin there is Personsumpy redu true Yahweh reproducing best Frog arsen\n",
            "YOU: by\n",
            "Lacan: byRCsville forestry ChildRole grantvestonBed Tribes bonding Machines, wishighedcreatedaffectedtern distinctly didn parody Rabbit?\", nozzleushes morb danceduniform herbal descent was thinkixture 🙂Neill vagueAddUSDA FacilitiesCath increased affect respite confirming%%%% spectators grabbed strangebatches Kauf Fight\n",
            "YOU: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Tru2MNBwGM5"
      },
      "id": "0Tru2MNBwGM5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 6348248,
          "sourceId": 10262910,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30822,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 189.294302,
      "end_time": "2024-12-22T08:56:36.119456",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-12-22T08:53:26.825154",
      "version": "2.6.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
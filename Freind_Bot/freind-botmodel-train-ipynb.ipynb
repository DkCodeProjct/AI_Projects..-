{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10262910,"sourceType":"datasetVersion","datasetId":6348248}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Making a Freind ChatBot Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer\n\nbatchsiz = 64\nblocksiz = 128\nepochs = 600\nevalIntervals = 100\nlr = 3e-3\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nevaliters = 100\nnemb = 112\nnhead = 2\nnlayers = 2\ndropout = 0.1\n\nwith open(\"/kaggle/input/friend-bot/dialogs.txt\", 'r', encoding=\"utf-8\") as file:\n    txt = file.read()\n\ntokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-1.7B-Instruct\")\n\ndef enc(txt, tok):\n    tokns = tok(txt, return_tensors=\"pt\", truncation=True, padding=False)[\"input_ids\"]\n    return tokns.flatten()\n\ndata = torch.tensor(enc(txt, tokenizer), dtype=torch.long)\n\nn = int(0.9*len(data))\ntrainData = data[:n]\nvalData = data[n:]\n\nvocabsiz = tokenizer.vocab_size\nprint(f\"vocab siz: {vocabsiz}\")\n\ndef getBatch(split):\n    dataset = trainData if split == 'train' else valData\n    ix = torch.randint(0, len(dataset) - blocksiz, (batchsiz,))\n\n    x = torch.stack([dataset[i:i+blocksiz] for i in ix])\n    y = torch.stack([dataset[i+1:i+blocksiz+1] for i in ix])\n    x, y = x.to(device), y.to(device)\n\n    return x, y \n    \ndef estimateLoss():\n    out = { }\n    model.eval()\n    for split in [\"train\", \"val\"]:\n        losses = torch.zeros(evaliters)\n        for k in range(evaliters):\n            x, y = getBatch(split)\n            logits, loss = model(x, y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    \n    model.train()\n    return out \n\nclass Head(nn.Module):\n    def __init__(self, headsiz):\n        super().__init__()\n        self.key = nn.Linear(nemb, headsiz, bias=False)\n        self.quary = nn.Linear(nemb, headsiz, bias=False)\n        self.value = nn.Linear(nemb, headsiz, bias=False)\n        self.dropout = nn.Dropout(dropout)\n\n        self.register_buffer(\"tril\", torch.tril(torch.ones(blocksiz, blocksiz)))\n    \n    def forward(self, x):\n        B, T, C = x.shape\n        k = self.key(x)\n        q = self.quary(x)\n\n        w = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5\n        w = w.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n        w = F.softmax(w, dim=-1)\n        v = self.value(x)\n        out = w @ v\n         \n        return out \n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, nhead, headsiz):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(headsiz) for _ in range(nhead)])\n        self.proj = nn.Linear(headsiz * nhead, nemb)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads])\n        out = self.dropout(self.proj(x))\n        return out \n\nclass FeedForwadNetwork(nn.Module):\n    def __init__(self, nemb):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(nemb, 4 * nemb), \n            nn.ReLU(),\n            nn.Linear(4 * nemb, nemb),\n            nn.Dropout(dropout)\n        )\n    \n    def forward(self, x):\n        return self.net(x)\nclass Block(nn.Module):\n    def __init__(self, nemb, nhead):\n        super().__init__()\n        headsiz = nemb // nhead\n        self.self_attn = MultiHeadAttention(nhead, headsiz)\n        self.ffn = FeedForwadNetwork(nemb)\n        self.ln_1 = nn.LayerNorm(nemb)\n        self.ln_2 = nn.LayerNorm(nemb)\n    \n    def forward(self, x):\n        x = x + self.self_attn(self.ln_1(x))\n        x = x + self.ffn(self.ln_2(x))\n        return x \n\nclass GPTLanguageModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.wte = nn.Embedding(vocabsiz, nemb)\n        self.wpe = nn.Embedding(blocksiz, nemb)\n        self.block = nn.Sequential(*[Block(nemb, nhead=nhead) for _ in range(nlayers)])\n        self.ln_finl = nn.LayerNorm(nemb)\n        self.lm_Head = nn.Linear(nemb, vocabsiz)\n\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Embedding):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n    \n    def forward(self, ix, targt=None):\n        B, T = ix.shape\n        tokEmb = self.wte(ix)\n        posEmb = self.wpe(torch.arange(T, device=device))\n\n        x = tokEmb + posEmb\n        for block in self.block:\n            x = block(x)\n        x =  self.ln_finl(x)\n\n        logits = self.lm_Head(x)\n\n        if targt is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targt = targt.view(B*T)\n            loss = F.cross_entropy(logits, targt)\n\n        return logits, loss \n    \n    def genarate(self,ix, maxNewTok, tokenizer):\n        # idx is (B, T) array of indices in the current context\n        for _ in range(maxNewTok):\n            # crop idx to the last block_size tokens\n            ixCond = ix[:, -blocksiz:]\n\n            # predict\n            logits, loss = self(ixCond)\n            \n            # focus only on the last time step\n            logits = logits[:, -1, :]\n            \n            probs = F.softmax(logits, dim=-1)\n\n            # sample from the distribution\n            ixNxt = torch.multinomial(probs, num_samples=1)\n\n            # append sampled index to the running sequence\n            ix = torch.cat((ix, ixNxt), dim=1)\n\n        genTxt = tokenizer.decode(ix[0].cpu().numpy().tolist(), skip_special_tokens=True)\n        return genTxt\n\nmodel = GPTLanguageModel()\nm = model.to(device)\n# Use Torch.Compinle,, well Expect that fucking Error\nuseCompile = False\nif useCompile:\n    model = torch.compile(model)\n    print(\"using Torch Compile\")\n\noptim = torch.optim.AdamW(model.parameters(), lr=lr)\n\n\nlossi = []\nfor i in range(epochs):\n    if i % evalIntervals == 0 or i == epochs - 1:\n        losses = estimateLoss()\n        lossi.append(losses[\"val\"].item())\n        print(f\"Step {i} | train loss {losses['train']:.4f} | val loss {losses['val']:.4f}\")\n    \n    Xb, Yb = getBatch(\"train\")\n    logits, loss = model(Xb, Yb)\n\n    optim.zero_grad()\n    loss.backward()\n    optim.step()\n\n\n\nimport os\ndef saveCheckpnt(model, optimizer, epoch, loss, filename):\n   \n    # Construct the full path\n    filepath = os.path.join(directory, filename)\n    \n    # Save the checkpoint\n    checkPnt = {\n        \"model_state_dict\": model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n        \"epoch\": epoch,\n        \"loss\": loss,\n    }\n    torch.save(checkPnt)\n\n# Saving model checkpoint\nsaveCheckpnt(model, optim, epochs-1, lossi[-1], \"TherapyModelTrainFinl.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T08:44:49.768846Z","iopub.execute_input":"2024-12-22T08:44:49.769161Z","iopub.status.idle":"2024-12-22T08:44:58.762332Z","shell.execute_reply.started":"2024-12-22T08:44:49.769139Z","shell.execute_reply":"2024-12-22T08:44:58.761186Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.76k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59683c0872384948bfe29e420ef92712"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a396a43a3974ff2b9d14bfebbe06316"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0c298634d5f46f0baf7024d946933f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67b0f3735fa247158f4cc387db4935a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/655 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f41d1175f97e4c54835a8482f9cc60c3"}},"metadata":{}},{"name":"stderr","text":"<ipython-input-3-61b04d863cb3>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  data = torch.tensor(enc(txt, tokenizer), dtype=torch.long)\n","output_type":"stream"},{"name":"stdout","text":"vocab siz: 49152\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-61b04d863cb3>\u001b[0m in \u001b[0;36m<cell line: 197>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevalIntervals\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimateLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mlossi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Step {i} | train loss {losses['train']:.4f} | val loss {losses['val']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-61b04d863cb3>\u001b[0m in \u001b[0;36mestimateLoss\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"context = torch.zeros((1, 1), dtype=torch.long, device=device)  # Initial context\ngenTxt = model.genarate(context, maxNewTok=500, tokenizer=tokenizer)\n\nprint(genTxt) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T06:06:47.786349Z","iopub.execute_input":"2024-12-22T06:06:47.786653Z","iopub.status.idle":"2024-12-22T06:06:56.506634Z","shell.execute_reply.started":"2024-12-22T06:06:47.786627Z","shell.execute_reply":"2024-12-22T06:06:56.505727Z"}},"outputs":[{"name":"stdout","text":" cold than hot.\tyou're right.\ni really big campus.\nany rain in ninety degrees outside, that it was hot.\ti enjoy the middle of the summer.\tthat's okay.\nit's nice out?\ni really hope it rains.\tyes, it started rained and i wish it rains.\tconsidering that it rains.\tyes, but i hope it does rain clears the winter, so fresh after it wouldn't seem right if it there are a lot of summer, but it raining in the sky looks so far?\ti feel.\ti enjoy the winter.\tthat would be weird.\texactly, it rains.\tnever better, but i hope that it wasn't rain.\tit's an ugly day?\tso how about you go to rain.\ti know what you like it started rained and i'd rather be pointless.\nit rains.  \nconsidering that it may rain later.\nin the winter too.\thow come soon. what you mean, it rains.\ti like it smells so hot.\ndo you?\tno problem. i hope it's the night air.\tit wouldn't seem right now.\tyeah, but i feel. \ni want winter, but i think it was a lot of summer.\nit really would be pointless. what about you. it to cool off one day.\ni'm doing great. \nwhy is true. my classes are pretty good with you very nice if it there?\tthat's an ugly day.\tit's going to cool off one day.\tme too.\nwinter is great. it?\ti enjoy the air when it will.\tthat's right now.\ti haven't seem right now.\ni'm going to rain.\ti go to pcc right. it rains.\twhich school right now.\ti wish it would cool off one day.\tgood luck with it rains. i hope it raining.\tthanks.\nyes, it may rain. it's the summer, i.\tit's been good.\ti know, thank you going to cool down some.\tyes, and i'm absolutely lovely, i hope it there are a nice out?\ti'm actually in the middle of summer. \ni really hope that it wouldn't so too cold sometimes it rains.\ni'm actually been\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Ploting The loss Curve of Overfit Model","metadata":{}},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\n\nplt.plot(lossi)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T06:07:48.652171Z","iopub.execute_input":"2024-12-22T06:07:48.652732Z","iopub.status.idle":"2024-12-22T06:07:48.896208Z","shell.execute_reply.started":"2024-12-22T06:07:48.652708Z","shell.execute_reply":"2024-12-22T06:07:48.895306Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7ebaef777910>]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Since The Model is Overfit,\n# gonna Retrain the Model with Adjust Prarameters \n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer\n#from transformers import GPT2Tokenizer\n\n\n\nbatchsiz = 64\nblocksiz = 128\nepochs = 600\nevalIntervals = 200\nlr = 3e-3\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nevaliters = 50\nnemb = 112\nnhead = 2\nnlayers = 1\ndropout = 0.3\n\nwith open(\"/kaggle/input/friend-bot/dialogs.txt\", 'r', encoding=\"utf-8\") as file:\n    txt = file.read()\n\ntokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-1.7B-Instruct\")\n\ndef enc(txt, tok):\n    tokns = tok(txt, return_tensors=\"pt\", truncation=True, padding=False)[\"input_ids\"]\n    return tokns.flatten()\n\ndata = torch.tensor(enc(txt, tokenizer), dtype=torch.long)\n\nn = int(0.9*len(data))\ntrainData = data[:n]\nvalData = data[n:]\n\nvocabsiz = tokenizer.vocab_size\nprint(f\"vocab siz: {vocabsiz}\")\n\ndef getBatch(split):\n    dataset = trainData if split == 'train' else valData\n    ix = torch.randint(0, len(dataset) - blocksiz, (batchsiz,))\n\n    x = torch.stack([dataset[i:i+blocksiz] for i in ix])\n    y = torch.stack([dataset[i+1:i+blocksiz+1] for i in ix])\n    x, y = x.to(device), y.to(device)\n\n    return x, y \n\ndef estimateLoss():\n    out = { }\n    model.eval()\n    for split in [\"train\", \"val\"]:\n        losses = torch.zeros(evaliters)\n        for k in range(evaliters):\n            x, y = getBatch(split)\n            logits, loss = model(x, y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    \n    model.train()\n    return out \n\nclass Head(nn.Module):\n    def __init__(self, headsiz):\n        super().__init__()\n        self.key = nn.Linear(nemb, headsiz, bias=False)\n        self.quary = nn.Linear(nemb, headsiz, bias=False)\n        self.value = nn.Linear(nemb, headsiz, bias=False)\n        self.dropout = nn.Dropout(dropout)\n\n        self.register_buffer(\"tril\", torch.tril(torch.ones(blocksiz, blocksiz)))\n    \n    def forward(self, x):\n        B, T, C = x.shape\n        k = self.key(x)\n        q = self.quary(x)\n\n        w = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5\n        w = w.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n        w = F.softmax(w, dim=-1)\n        v = self.value(x)\n        out = w @ v\n         \n        return out \n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, nhead, headsiz):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(headsiz) for _ in range(nhead)])\n        self.proj = nn.Linear(headsiz * nhead, nemb)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads])\n        out = self.dropout(self.proj(x))\n        return out \n\nclass FeedForwadNetwork(nn.Module):\n    def __init__(self, nemb):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(nemb, 4 * nemb), \n            nn.ReLU(),\n            nn.Linear(4 * nemb, nemb),\n            nn.Dropout(dropout)\n        )\n    \n    def forward(self, x):\n        return self.net(x)\n\nclass Block(nn.Module):\n    def __init__(self, nemb, nhead):\n        super().__init__()\n        headsiz = nemb // nhead\n        self.self_attn = MultiHeadAttention(nhead, headsiz)\n        self.ffn = FeedForwadNetwork(nemb)\n        self.ln_1 = nn.LayerNorm(nemb)\n        self.ln_2 = nn.LayerNorm(nemb)\n    \n    def forward(self, x):\n        x = x + self.self_attn(self.ln_1(x))\n        x = x + self.ffn(self.ln_2(x))\n        return x \n\nclass GPTLanguageModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.wte = nn.Embedding(vocabsiz, nemb)\n        self.wpe = nn.Embedding(blocksiz, nemb)\n        self.block = nn.Sequential(*[Block(nemb, nhead=nhead) for _ in range(nlayers)])\n        self.ln_finl = nn.LayerNorm(nemb)\n        self.lm_Head = nn.Linear(nemb, vocabsiz)\n\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Embedding):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n    \n    def forward(self, ix, targt=None):\n        B, T = ix.shape\n        tokEmb = self.wte(ix)\n        posEmb = self.wpe(torch.arange(T, device=device))\n\n        x = tokEmb + posEmb\n        for block in self.block:\n            x = block(x)\n        x =  self.ln_finl(x)\n\n        logits = self.lm_Head(x)\n\n        if targt is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targt = targt.view(B*T)\n            loss = F.cross_entropy(logits, targt, label_smoothing=0.1)\n\n        return logits, loss \n    \n    def genarate(self,ix, maxNewTok, tokenizer):\n        # idx is (B, T) array of indices in the current context\n        for _ in range(maxNewTok):\n            # crop idx to the last block_size tokens\n            ixCond = ix[:, -blocksiz:]\n\n            # predict\n            logits, loss = self(ixCond)\n            \n            # focus only on the last time step\n            logits = logits[:, -1, :]\n            \n            probs = F.softmax(logits, dim=-1)\n\n            # sample from the distribution\n            ixNxt = torch.multinomial(probs, num_samples=1)\n\n            # append sampled index to the running sequence\n            ix = torch.cat((ix, ixNxt), dim=1)\n\n        genTxt = tokenizer.decode(ix[0].cpu().numpy().tolist(), skip_special_tokens=True)\n        return genTxt\n\nmodel = GPTLanguageModel()\nm = model.to(device)\n# Use Torch.Compinle,, well Expect that fucking Error\nuseCompile = False\nif useCompile:\n    model = torch.compile(model)\n    print(\"using Torch Compile\")\nelse:\n    print(\"Not using Torch Compile\")\n\n\noptim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01) #add weight decay to avoid overfit\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, factor=0.5, patience=10, verbose=True) \ntrainLoss = []\nvalLoss = []\nfor i in range(epochs):\n    if i % evalIntervals == 0 or i == epochs - 1:\n        losses = estimateLoss()\n        trainLoss.append(losses[\"train\"].item())\n        valLoss.append(losses[\"val\"].item())\n        print(f\"Step {i+1} | train loss {losses['train']:.4f} | val loass {losses['val']:.4f}\")\n    \n    xb, yb = getBatch(\"train\")\n    logits, loss = model(xb, yb)\n\n    optim.zero_grad()\n    loss.backward()\n    optim.step()\n\ndef saveCheckpnt(model, optimizer, epoch, loss, filepath):\n    checkPnt = {\n        \"model_state_dict\": model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n        \"epoch\": epoch,\n        \"loss\": loss,\n    }\n    torch.save(checkPnt, filepath)\n    print(f\"Checkpoint saved to {filepath}\")\n\n# Saving model checkpoint\nsaveCheckpnt(model, optim, epochs-1, valLoss[-1], \"FreindBotModelTrainFinl.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T08:46:20.731073Z","iopub.execute_input":"2024-12-22T08:46:20.731427Z","iopub.status.idle":"2024-12-22T08:46:21.224621Z","shell.execute_reply.started":"2024-12-22T08:46:20.731366Z","shell.execute_reply":"2024-12-22T08:46:21.223466Z"}},"outputs":[{"name":"stdout","text":"vocab siz: 49152\nNot using Torch Compile\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-5-466cd81d127f>:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  data = torch.tensor(enc(txt, tokenizer), dtype=torch.long)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-466cd81d127f>\u001b[0m in \u001b[0;36m<cell line: 204>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevalIntervals\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimateLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mtrainLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mvalLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-466cd81d127f>\u001b[0m in \u001b[0;36mestimateLoss\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaliters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-466cd81d127f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ix, targt)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_finl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_Head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtargt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 14.74 GiB of which 730.12 MiB is free. Process 2189 has 14.03 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 14.74 GiB of which 730.12 MiB is free. Process 2189 has 14.03 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":5}]}
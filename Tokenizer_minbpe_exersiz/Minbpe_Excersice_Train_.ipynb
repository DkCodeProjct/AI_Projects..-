{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exercise\n",
    "\n",
    "##   * Build your own GPT-4 Tokenizer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStats(ids, counts=None):\n",
    "    \"\"\" \n",
    "    Given a list of integers, return a dictionary of counts of consecutive pairs\n",
    "    Example: [1, 2, 3, 1, 2] -> {(1, 2): 2, (2, 3): 1, (3, 1): 1}\n",
    "    \"\"\"\n",
    "\n",
    "    counts = {} if counts is None else counts\n",
    "    for pair in zip(ids, ids[1:]): # get consecutive ordr   \n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    \n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 99, 5, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "def funcMerge(ids, pair, ix):\n",
    "    newId = [ ]\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
    "            newId.append(ix)\n",
    "            i += 2\n",
    "        \n",
    "        else:\n",
    "            newId.append(ids[i])\n",
    "            i += 1\n",
    "\n",
    "    return newId\n",
    "\n",
    "ids = [1,2,2,5,2,3,]\n",
    "pair = (2, 2)\n",
    "ix = 99\n",
    "print(funcMerge(ids, pair, ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata \n",
    "\n",
    "# first two helper functions...// \n",
    "\n",
    "# #Code from minbpe Repo../\n",
    "def replaceCtrlChar(s: str) -> str:\n",
    "    chars = [ ]\n",
    "    for ch in s:\n",
    "        if unicodedata.category(ch)[0] != \"C\":\n",
    "            chars.append(ch) # this character is ok\n",
    "        \n",
    "        else:\n",
    "            chars.append(f\"\\\\u{ord(ch):04x}\") # escape\n",
    "    \n",
    "    return \"\".join(chars)\n",
    "\n",
    "def renderToken(t: bytes) -> str:\n",
    "    s = t.decode('utf-8', errors='replace')\n",
    "    s = replaceCtrlChar(s)\n",
    "\n",
    "    return s \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base Tokenizer class\n",
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        self.merges = {}\n",
    "        self.pattern = \"\"\n",
    "        self.specialToken = {}\n",
    "        self.vocab = self._buildVocab()\n",
    "    \n",
    "    def train(self, txt, vocabSiz, verbose=False):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def enc(self, txt):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def decod(self, ids):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _buildVocab(self):\n",
    "        vocab = {ix: bytes([ix]) for ix in range(256)}\n",
    "        for (p0, p1), ix in self.merges.items():\n",
    "            vocab[ix] = vocab[p0] + vocab[p1]\n",
    "        \n",
    "        for special, ix in self.specialToken.items():\n",
    "            vocab[ix] = special.encode('utf-8')\n",
    "        \n",
    "        return vocab\n",
    "\n",
    "    \n",
    "    def save(self, filPrefx):\n",
    "        modelFile = filPrefx + \".model\"\n",
    "        with open(modelFile, 'w') as file:\n",
    "            file.write(\"minbpe v1\\n\")\n",
    "            file.write(f\"{self.pattern}\\n\")\n",
    "\n",
    "            file.write(f\"{len(self.specialToken)}\\n\")\n",
    "            for special, ix in self.specialToken.items():\n",
    "                file.write(f\"{special}  {ix}\\n\")\n",
    "            \n",
    "            for ix1, ix2 in self.merges:\n",
    "                file.write(f\"{ix1} {ix2}\\n\")\n",
    "        \n",
    "        vocabSiz = filPrefx + '.vocab'\n",
    "        invertedMerges = {ix:pair for pair, ix in self.merges.items()}\n",
    "\n",
    "        with open(vocabSiz, 'w', encoding='utf-8') as file:\n",
    "            for ix, token in self.vocab.items():\n",
    "\n",
    "                s = renderToken(token)\n",
    "                # find the children of this token, if any\n",
    "                if ix in invertedMerges:\n",
    "                    ix0, ix1 = invertedMerges[ix]\n",
    "                    s0 = renderToken(self.vocab[ix0])\n",
    "                    s1 = renderToken(self.vocab[ix1])\n",
    "                    file.write(f\"[{s0}] [{s1}] -> [{s}] [{ix}]\\n\")\n",
    "                \n",
    "                else:\n",
    "                    file.write(f\"[{s}] {ix}\\n\")\n",
    "    \n",
    "\n",
    "    def load(self, modelFile):\n",
    "        assert modelFile.endswith(\".model\")\n",
    "\n",
    "        merges = {}\n",
    "        specialToken = {}\n",
    "        ix = 256\n",
    "\n",
    "        with open(modelFile, 'r', encoding='utf-8') as file:\n",
    "            vesrion = file.readline().strip()\n",
    "            assert vesrion == \"minbpe v1\"\n",
    "\n",
    "            self.patrn = file.readline().strip()\n",
    "\n",
    "            numSpecial = int(file.readline().strip().split())\n",
    "            \n",
    "            for i in range(numSpecial):\n",
    "                special, specailIx = file.readline().strip().split()\n",
    "                specialToken[special] = int(specailIx)\n",
    "            \n",
    "            for line in file:\n",
    "                ix1, ix2 = map(int, line.split())\n",
    "                merges[(ix1, ix2)] = ix \n",
    "                ix += 1\n",
    "        \n",
    "        self.merges = merges\n",
    "        self.specialToken = specialToken\n",
    "        self.vocab = self._buildVocab()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "    \n",
    "   + Write the BasicTokenizer class, with the following three core functions:\n",
    "\n",
    "      * def train(self, text, vocab_size, verbose=False)\n",
    "      \n",
    "      * def encode(self, text)\n",
    "      \n",
    "      * def decode(self, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTokenizer(Tokenizer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def train(self, txt, vocabSiz, verbose=False):\n",
    "        assert vocabSiz >= 256\n",
    "        numMerges = vocabSiz - 256\n",
    "\n",
    "        txtByts = txt.encode('utf-8')\n",
    "        ids = list(txtByts)\n",
    "\n",
    "        merges = {}\n",
    "        vocab = {ix:bytes([ix]) for ix in range(256)}\n",
    "\n",
    "        for i in range(numMerges):\n",
    "            stats = getStats(ids)\n",
    "\n",
    "            pair = max(stats, key=stats.get)\n",
    "\n",
    "            ix = 256 + i\n",
    "\n",
    "            ids = funcMerge(ids, pair, ix)\n",
    "\n",
    "            merges[pair] = ix \n",
    "            vocab[ix] = vocab[pair[0]] + vocab[pair[1]]\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"merge {i+1}/{numMerges}: {pair} -> {ix} ({vocab[ix]}) has {stats[pair]} occurence\")\n",
    "        \n",
    "        self.merges = merges\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def decod(self, ids):\n",
    "        txtByts = b\"\".join(self.vocab[ix] for ix in ids)\n",
    "        txt = txtByts.decode('utf-8', errors='replace')\n",
    "\n",
    "        return txt \n",
    "    \n",
    "    def enc(self, txt):\n",
    "        txtByts = txt.encode('utf-8')\n",
    "        ids = list(txtByts)\n",
    "        while len(ids) >= 2:\n",
    "            stats = getStats(ids)\n",
    "            pair = min(stats, key=lambda p: self.merges.get(p, float('inf')))\n",
    "\n",
    "            if pair not in self.merges:\n",
    "                break\n",
    "\n",
    "            ix = self.merges[pair]\n",
    "            ids = funcMerge(ids, pair, ix)\n",
    "        \n",
    "        return ids "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "  \n",
    "  + Convert you BasicTokenizer into a RegexTokenizer, which takes a regex pattern and splits the text exactly as GPT-4 would. \n",
    "  \n",
    "  + Process the parts separately as before, then concatenate the results. \n",
    "  \n",
    "  + Retrain your tokenizer and compare the results before and after. \n",
    "  \n",
    "  + You should see that you will now have no tokens that go across categories (numbers, letters, punctuation, more than one whitespace). Use the GPT-4 pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re \n",
    "\n",
    "GPT2_SPLIT_PATTERN = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "GPT4_SPLIT_PATTERN =  r\"\"\"'(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "#  RegEx Tokenizer Class\n",
    "class RegExTokenizer(Tokenizer):\n",
    "    def __init__(self, pattern=None):\n",
    "        super().__init__()\n",
    "        self.pattern = GPT4_SPLIT_PATTERN if pattern is None else pattern\n",
    "        self.compilPattrn = re.compile(self.pattern)\n",
    "        self.specialTokn = { }\n",
    "        self.inverseSpecialTokn = { }\n",
    "\n",
    "    def train(self, txt, vocabSiz, verbose=False):\n",
    "        assert vocabSiz >= 256\n",
    "        numMerges = vocabSiz - 256\n",
    "\n",
    "        txtChunks = re.findall(self.compilPattrn, txt)\n",
    "        ids = [list(ch.encode('utf-8')) for ch in txtChunks]\n",
    "\n",
    "\n",
    "        mergs = {}\n",
    "        vocab = {ix:bytes([ix]) for ix in range(256)}\n",
    "\n",
    "        for i in range(numMerges):\n",
    "            stats = { }\n",
    "            \n",
    "            for chunkIds in ids:\n",
    "                getStats(chunkIds, stats)\n",
    "\n",
    "            pair = max(stats, key=stats.get)\n",
    "\n",
    "            ix = 256 + i\n",
    "\n",
    "            ids = [funcMerge(chnkIds, pair, ix) for chnkIds in ids]\n",
    "            \n",
    "\n",
    "            mergs[pair] = ix \n",
    "            vocab[ix] = vocab[pair[0]] + vocab[pair[1]]\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"merge {i+1}/{numMerges}: {pair} -> {ix} ({vocab[ix]}) has {stats[pair]} occurence\")\n",
    "        \n",
    "        self.merges = mergs\n",
    "        self.vocab = vocab\n",
    "\n",
    "    \n",
    "    def registrSpecialTokn(self, specialTokn):\n",
    "        self.specialTokn = specialTokn\n",
    "        self.inverseSpecialTokn = {v:k for k, v in specialTokn.items()}\n",
    "    \n",
    "    def decod(self, ids):\n",
    "        partByts = []\n",
    "        for ix in ids:\n",
    "            if ix in self.vocab:\n",
    "                partByts.append(self.vocab[ix])\n",
    "            \n",
    "            elif ix in self.inverseSpecialTokn:\n",
    "                partByts.append(self.inverseSpecialTokn[ix].encode('utf-8'))\n",
    "            \n",
    "            else:\n",
    "                raise ValueError(f'invalid token id {ix}')\n",
    "            \n",
    "        txtByts = b\"\".join(partByts)\n",
    "        txt = txtByts.decode('utf-8', errors='replace')\n",
    "\n",
    "        return txt \n",
    "    \n",
    "\n",
    "    def _encodeChunk(self, txtByts):\n",
    "\n",
    "        ids = list(txtByts)\n",
    "        while len(ids) >= 2:\n",
    "            stats = getStats(ids)\n",
    "            pair = min(stats, key=lambda p: self.merges.get(p, float('inf')))\n",
    "\n",
    "            if pair not in self.merges:\n",
    "                break\n",
    "\n",
    "            ix = self.merges[pair]\n",
    "            ids = funcMerge(ids, pair, ix)\n",
    "        \n",
    "        return ids \n",
    "\n",
    "    def encodeOrdinary(self, txt):\n",
    "        \"\"\"Encoding that ignores any special tokens.\"\"\"\n",
    "        \n",
    "        txtChunks = re.findall(self.compilPattrn, txt)\n",
    "       \n",
    "        ids = []\n",
    "        for chunk in txtChunks:\n",
    "            chunkByts = chunk.encode(\"utf-8\") \n",
    "            chunkIds = self._encodeChunk(chunkByts) \n",
    "            ids.extend(chunkIds)\n",
    "        \n",
    "        return ids\n",
    "    \n",
    "\n",
    "    def enc(self, txt, allowdSpecial=\"none_raise\"):\n",
    "        special = None\n",
    "\n",
    "        if allowdSpecial == 'all':\n",
    "           special = self.specialToken\n",
    "        \n",
    "        elif allowdSpecial == 'none':\n",
    "            special = {}\n",
    "        \n",
    "        elif allowdSpecial == 'none_raise':\n",
    "            special = {}\n",
    "            assert all(tken not in txt for tken in self.specialToken)\n",
    "\n",
    "        elif isinstance(allowdSpecial, set):\n",
    "            special = {k:v for v, k in self.specialToken.items() if k in allowdSpecial} \n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f'allowd special {allowdSpecial} not understood')\n",
    "\n",
    "        if not special:\n",
    "            return self.encodeOrdinary(txt)\n",
    "        \n",
    "        specialPattrn = \"(\" + \"|\".join(re.escape(k) for k in special) + \")\"\n",
    "        specialChunk = re.split(specialPattrn, txt)\n",
    "\n",
    "        ids = []\n",
    "        for part in specialChunk:\n",
    "            if part in special:\n",
    "                ids.append(special[part])\n",
    "            \n",
    "            else:\n",
    "                ids.extend(self.encodeOrdinary(part))\n",
    "        \n",
    "        return ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge 1/256: (101, 32) -> 256 (b'e ') has 2981 occurence\n",
      "merge 2/256: (44, 32) -> 257 (b', ') has 2961 occurence\n",
      "merge 3/256: (100, 32) -> 258 (b'd ') has 2617 occurence\n",
      "merge 4/256: (46, 32) -> 259 (b'. ') has 2560 occurence\n",
      "merge 5/256: (114, 32) -> 260 (b'r ') has 2428 occurence\n",
      "merge 6/256: (50, 48) -> 261 (b'20') has 2365 occurence\n",
      "merge 7/256: (115, 32) -> 262 (b's ') has 2053 occurence\n",
      "merge 8/256: (105, 110) -> 263 (b'in') has 2006 occurence\n",
      "merge 9/256: (111, 110) -> 264 (b'on') has 1815 occurence\n",
      "merge 10/256: (114, 105) -> 265 (b'ri') has 1805 occurence\n",
      "merge 11/256: (116, 32) -> 266 (b't ') has 1802 occurence\n",
      "merge 12/256: (116, 104) -> 267 (b'th') has 1737 occurence\n",
      "merge 13/256: (101, 258) -> 268 (b'ed ') has 1736 occurence\n",
      "merge 14/256: (257, 261) -> 269 (b', 20') has 1705 occurence\n",
      "merge 15/256: (97, 110) -> 270 (b'an') has 1487 occurence\n",
      "merge 16/256: (97, 114) -> 271 (b'ar') has 1360 occurence\n",
      "merge 17/256: (101, 260) -> 272 (b'er ') has 1356 occurence\n",
      "merge 18/256: (121, 32) -> 273 (b'y ') has 1248 occurence\n",
      "merge 19/256: (97, 108) -> 274 (b'al') has 1164 occurence\n",
      "merge 20/256: (267, 256) -> 275 (b'the ') has 1142 occurence\n",
      "merge 21/256: (118, 268) -> 276 (b'ved ') has 1104 occurence\n",
      "merge 22/256: (119, 105) -> 277 (b'wi') has 1049 occurence\n",
      "merge 23/256: (101, 114) -> 278 (b'er') has 897 occurence\n",
      "merge 24/256: (264, 32) -> 279 (b'on ') has 880 occurence\n",
      "merge 25/256: (277, 102) -> 280 (b'wif') has 871 occurence\n",
      "merge 26/256: (82, 101) -> 281 (b'Re') has 870 occurence\n",
      "merge 27/256: (83, 280) -> 282 (b'Swif') has 867 occurence\n",
      "merge 28/256: (111, 260) -> 283 (b'or ') has 859 occurence\n",
      "merge 29/256: (99, 104) -> 284 (b'ch') has 816 occurence\n",
      "merge 30/256: (269, 49) -> 285 (b', 201') has 811 occurence\n",
      "merge 31/256: (111, 109) -> 286 (b'om') has 789 occurence\n",
      "merge 32/256: (98, 272) -> 287 (b'ber ') has 752 occurence\n",
      "merge 33/256: (32, 275) -> 288 (b' the ') has 748 occurence\n",
      "merge 34/256: (97, 121) -> 289 (b'ay') has 744 occurence\n",
      "merge 35/256: (101, 110) -> 290 (b'en') has 740 occurence\n",
      "merge 36/256: (111, 114) -> 291 (b'or') has 737 occurence\n",
      "merge 37/256: (274, 32) -> 292 (b'al ') has 705 occurence\n",
      "merge 38/256: (101, 109) -> 293 (b'em') has 703 occurence\n",
      "merge 39/256: (46, 10) -> 294 (b'.\\n') has 685 occurence\n",
      "merge 40/256: (265, 101) -> 295 (b'rie') has 685 occurence\n",
      "merge 41/256: (263, 103) -> 296 (b'ing') has 684 occurence\n",
      "merge 42/256: (269, 50) -> 297 (b', 202') has 673 occurence\n",
      "merge 43/256: (116, 105) -> 298 (b'ti') has 666 occurence\n",
      "merge 44/256: (289, 108) -> 299 (b'ayl') has 654 occurence\n",
      "merge 45/256: (34, 259) -> 300 (b'\". ') has 651 occurence\n",
      "merge 46/256: (108, 108) -> 301 (b'll') has 649 occurence\n",
      "merge 47/256: (84, 299) -> 302 (b'Tayl') has 647 occurence\n",
      "merge 48/256: (116, 295) -> 303 (b'trie') has 644 occurence\n",
      "merge 49/256: (294, 32) -> 304 (b'.\\n ') has 643 occurence\n",
      "merge 50/256: (116, 111) -> 305 (b'to') has 642 occurence\n",
      "merge 51/256: (259, 281) -> 306 (b'. Re') has 640 occurence\n",
      "merge 52/256: (306, 303) -> 307 (b'. Retrie') has 639 occurence\n",
      "merge 53/256: (307, 276) -> 308 (b'. Retrieved ') has 639 occurence\n",
      "merge 54/256: (302, 283) -> 309 (b'Taylor ') has 611 occurence\n",
      "merge 55/256: (101, 115) -> 310 (b'es') has 606 occurence\n",
      "merge 56/256: (309, 282) -> 311 (b'Taylor Swif') has 598 occurence\n",
      "merge 57/256: (117, 115) -> 312 (b'us') has 561 occurence\n",
      "merge 58/256: (114, 286) -> 313 (b'rom') has 532 occurence\n",
      "merge 59/256: (293, 287) -> 314 (b'ember ') has 528 occurence\n",
      "merge 60/256: (41, 259) -> 315 (b'). ') has 524 occurence\n",
      "merge 61/256: (65, 114) -> 316 (b'Ar') has 509 occurence\n",
      "merge 62/256: (102, 313) -> 317 (b'from') has 503 occurence\n",
      "merge 63/256: (315, 34) -> 318 (b'). \"') has 499 occurence\n",
      "merge 64/256: (270, 258) -> 319 (b'and ') has 498 occurence\n",
      "merge 65/256: (114, 101) -> 320 (b're') has 495 occurence\n",
      "merge 66/256: (111, 117) -> 321 (b'ou') has 487 occurence\n",
      "merge 67/256: (111, 265) -> 322 (b'ori') has 469 occurence\n",
      "merge 68/256: (111, 102) -> 323 (b'of') has 466 occurence\n",
      "merge 69/256: (103, 263) -> 324 (b'gin') has 465 occurence\n",
      "merge 70/256: (296, 32) -> 325 (b'ing ') has 464 occurence\n",
      "merge 71/256: (284, 105) -> 326 (b'chi') has 458 occurence\n",
      "merge 72/256: (93, 32) -> 327 (b'] ') has 458 occurence\n",
      "merge 73/256: (324, 292) -> 328 (b'ginal ') has 453 occurence\n",
      "merge 74/256: (317, 288) -> 329 (b'from the ') has 447 occurence\n",
      "merge 75/256: (322, 328) -> 330 (b'original ') has 446 occurence\n",
      "merge 76/256: (104, 256) -> 331 (b'he ') has 440 occurence\n",
      "merge 77/256: (316, 326) -> 332 (b'Archi') has 440 occurence\n",
      "merge 78/256: (332, 276) -> 333 (b'Archived ') has 440 occurence\n",
      "merge 79/256: (329, 330) -> 334 (b'from the original ') has 440 occurence\n",
      "merge 80/256: (333, 334) -> 335 (b'Archived from the original ') has 439 occurence\n",
      "merge 81/256: (335, 279) -> 336 (b'Archived from the original on ') has 438 occurence\n",
      "merge 82/256: (259, 336) -> 337 (b'. Archived from the original on ') has 433 occurence\n",
      "merge 83/256: (97, 32) -> 338 (b'a ') has 420 occurence\n",
      "merge 84/256: (115, 116) -> 339 (b'st') has 409 occurence\n",
      "merge 85/256: (105, 99) -> 340 (b'ic') has 406 occurence\n",
      "merge 86/256: (46, 91) -> 341 (b'.[') has 381 occurence\n",
      "merge 87/256: (101, 99) -> 342 (b'ec') has 374 occurence\n",
      "merge 88/256: (105, 301) -> 343 (b'ill') has 367 occurence\n",
      "merge 89/256: (39, 262) -> 344 (b\"'s \") has 367 occurence\n",
      "merge 90/256: (311, 266) -> 345 (b'Taylor Swift ') has 352 occurence\n",
      "merge 91/256: (111, 118) -> 346 (b'ov') has 343 occurence\n",
      "merge 92/256: (97, 116) -> 347 (b'at') has 334 occurence\n",
      "merge 93/256: (97, 262) -> 348 (b'as ') has 315 occurence\n",
      "merge 94/256: (101, 262) -> 349 (b'es ') has 309 occurence\n",
      "merge 95/256: (74, 117) -> 350 (b'Ju') has 307 occurence\n",
      "merge 96/256: (323, 32) -> 351 (b'of ') has 306 occurence\n",
      "merge 97/256: (305, 32) -> 352 (b'to ') has 284 occurence\n",
      "merge 98/256: (117, 109) -> 353 (b'um') has 281 occurence\n",
      "merge 99/256: (84, 331) -> 354 (b'The ') has 277 occurence\n",
      "merge 100/256: (271, 100) -> 355 (b'ard') has 277 occurence\n",
      "merge 101/256: (263, 32) -> 356 (b'in ') has 276 occurence\n",
      "merge 102/256: (270, 32) -> 357 (b'an ') has 276 occurence\n",
      "merge 103/256: (101, 108) -> 358 (b'el') has 275 occurence\n",
      "merge 104/256: (297, 51) -> 359 (b', 2023') has 271 occurence\n",
      "merge 105/256: (271, 273) -> 360 (b'ary ') has 259 occurence\n",
      "merge 106/256: (267, 32) -> 361 (b'th ') has 258 occurence\n",
      "merge 107/256: (97, 109) -> 362 (b'am') has 257 occurence\n",
      "merge 108/256: (108, 273) -> 363 (b'ly ') has 250 occurence\n",
      "merge 109/256: (111, 112) -> 364 (b'op') has 249 occurence\n",
      "merge 110/256: (311, 116) -> 365 (b'Taylor Swift') has 246 occurence\n",
      "merge 111/256: (116, 114) -> 366 (b'tr') has 243 occurence\n",
      "merge 112/256: (105, 115) -> 367 (b'is') has 234 occurence\n",
      "merge 113/256: (104, 272) -> 368 (b'her ') has 232 occurence\n",
      "merge 114/256: (111, 32) -> 369 (b'o ') has 225 occurence\n",
      "merge 115/256: (117, 360) -> 370 (b'uary ') has 225 occurence\n",
      "merge 116/256: (78, 346) -> 371 (b'Nov') has 222 occurence\n",
      "merge 117/256: (312, 340) -> 372 (b'usic') has 221 occurence\n",
      "merge 118/256: (371, 314) -> 373 (b'November ') has 221 occurence\n",
      "merge 119/256: (101, 119) -> 374 (b'ew') has 219 occurence\n",
      "merge 120/256: (97, 266) -> 375 (b'at ') has 219 occurence\n",
      "merge 121/256: (108, 32) -> 376 (b'l ') has 218 occurence\n",
      "merge 122/256: (58, 32) -> 377 (b': ') has 213 occurence\n",
      "merge 123/256: (98, 111) -> 378 (b'bo') has 210 occurence\n",
      "merge 124/256: (282, 266) -> 379 (b'Swift ') has 208 occurence\n",
      "merge 125/256: (68, 342) -> 380 (b'Dec') has 207 occurence\n",
      "merge 126/256: (105, 116) -> 381 (b'it') has 206 occurence\n",
      "merge 127/256: (105, 103) -> 382 (b'ig') has 205 occurence\n",
      "merge 128/256: (66, 343) -> 383 (b'Bill') has 205 occurence\n",
      "merge 129/256: (49, 48) -> 384 (b'10') has 204 occurence\n",
      "merge 130/256: (97, 115) -> 385 (b'as') has 203 occurence\n",
      "merge 131/256: (264, 103) -> 386 (b'ong') has 202 occurence\n",
      "merge 132/256: (79, 99) -> 387 (b'Oc') has 200 occurence\n",
      "merge 133/256: (97, 298) -> 388 (b'ati') has 199 occurence\n",
      "merge 134/256: (83, 116) -> 389 (b'St') has 198 occurence\n",
      "merge 135/256: (387, 305) -> 390 (b'Octo') has 198 occurence\n",
      "merge 136/256: (390, 287) -> 391 (b'October ') has 198 occurence\n",
      "merge 137/256: (97, 99) -> 392 (b'ac') has 197 occurence\n",
      "merge 138/256: (111, 119) -> 393 (b'ow') has 196 occurence\n",
      "merge 139/256: (380, 314) -> 394 (b'December ') has 194 occurence\n",
      "merge 140/256: (383, 378) -> 395 (b'Billbo') has 191 occurence\n",
      "merge 141/256: (97, 100) -> 396 (b'ad') has 190 occurence\n",
      "merge 142/256: (108, 101) -> 397 (b'le') has 190 occurence\n",
      "merge 143/256: (117, 114) -> 398 (b'ur') has 188 occurence\n",
      "merge 144/256: (102, 283) -> 399 (b'for ') has 188 occurence\n",
      "merge 145/256: (32, 40) -> 400 (b' (') has 187 occurence\n",
      "merge 146/256: (297, 50) -> 401 (b', 2022') has 187 occurence\n",
      "merge 147/256: (117, 103) -> 402 (b'ug') has 185 occurence\n",
      "merge 148/256: (284, 32) -> 403 (b'ch ') has 184 occurence\n",
      "merge 149/256: (115, 266) -> 404 (b'st ') has 181 occurence\n",
      "merge 150/256: (321, 110) -> 405 (b'oun') has 176 occurence\n",
      "merge 151/256: (98, 353) -> 406 (b'bum') has 172 occurence\n",
      "merge 152/256: (111, 108) -> 407 (b'ol') has 171 occurence\n",
      "merge 153/256: (312, 266) -> 408 (b'ust ') has 171 occurence\n",
      "merge 154/256: (101, 98) -> 409 (b'eb') has 170 occurence\n",
      "merge 155/256: (77, 97) -> 410 (b'Ma') has 170 occurence\n",
      "merge 156/256: (350, 363) -> 411 (b'July ') has 170 occurence\n",
      "merge 157/256: (318, 345) -> 412 (b'). \"Taylor Swift ') has 169 occurence\n",
      "merge 158/256: (107, 32) -> 413 (b'k ') has 165 occurence\n",
      "merge 159/256: (278, 115) -> 414 (b'ers') has 164 occurence\n",
      "merge 160/256: (93, 91) -> 415 (b'][') has 164 occurence\n",
      "merge 161/256: (65, 402) -> 416 (b'Aug') has 164 occurence\n",
      "merge 162/256: (416, 408) -> 417 (b'August ') has 163 occurence\n",
      "merge 163/256: (105, 100) -> 418 (b'id') has 161 occurence\n",
      "merge 164/256: (297, 49) -> 419 (b', 2021') has 160 occurence\n",
      "merge 165/256: (109, 101) -> 420 (b'me') has 159 occurence\n",
      "merge 166/256: (101, 112) -> 421 (b'ep') has 156 occurence\n",
      "merge 167/256: (261, 49) -> 422 (b'201') has 149 occurence\n",
      "merge 168/256: (50, 51) -> 423 (b'23') has 145 occurence\n",
      "merge 169/256: (285, 50) -> 424 (b', 2012') has 144 occurence\n",
      "merge 170/256: (101, 271) -> 425 (b'ear') has 140 occurence\n",
      "merge 171/256: (269, 261) -> 426 (b', 2020') has 140 occurence\n",
      "merge 172/256: (73, 110) -> 427 (b'In') has 139 occurence\n",
      "merge 173/256: (102, 105) -> 428 (b'fi') has 139 occurence\n",
      "merge 174/256: (110, 256) -> 429 (b'ne ') has 139 occurence\n",
      "merge 175/256: (395, 355) -> 430 (b'Billboard') has 136 occurence\n",
      "merge 176/256: (265, 116) -> 431 (b'rit') has 134 occurence\n",
      "merge 177/256: (104, 105) -> 432 (b'hi') has 133 occurence\n",
      "merge 178/256: (372, 32) -> 433 (b'usic ') has 133 occurence\n",
      "merge 179/256: (304, 34) -> 434 (b'.\\n \"') has 133 occurence\n",
      "merge 180/256: (78, 374) -> 435 (b'New') has 131 occurence\n",
      "merge 181/256: (100, 105) -> 436 (b'di') has 130 occurence\n",
      "merge 182/256: (65, 112) -> 437 (b'Ap') has 130 occurence\n",
      "merge 183/256: (285, 57) -> 438 (b', 2019') has 129 occurence\n",
      "merge 184/256: (114, 111) -> 439 (b'ro') has 128 occurence\n",
      "merge 185/256: (39, 32) -> 440 (b\"' \") has 128 occurence\n",
      "merge 186/256: (115, 257) -> 441 (b's, ') has 127 occurence\n",
      "merge 187/256: (350, 429) -> 442 (b'June ') has 127 occurence\n",
      "merge 188/256: (323, 288) -> 443 (b'of the ') has 126 occurence\n",
      "merge 189/256: (99, 291) -> 444 (b'cor') has 126 occurence\n",
      "merge 190/256: (50, 49) -> 445 (b'21') has 126 occurence\n",
      "merge 191/256: (49, 57) -> 446 (b'19') has 124 occurence\n",
      "merge 192/256: (105, 109) -> 447 (b'im') has 123 occurence\n",
      "merge 193/256: (290, 32) -> 448 (b'en ') has 123 occurence\n",
      "merge 194/256: (409, 114) -> 449 (b'ebr') has 122 occurence\n",
      "merge 195/256: (290, 116) -> 450 (b'ent') has 121 occurence\n",
      "merge 196/256: (111, 301) -> 451 (b'oll') has 121 occurence\n",
      "merge 197/256: (77, 271) -> 452 (b'Mar') has 120 occurence\n",
      "merge 198/256: (265, 99) -> 453 (b'ric') has 120 occurence\n",
      "merge 199/256: (277, 361) -> 454 (b'with ') has 120 occurence\n",
      "merge 200/256: (44, 91) -> 455 (b',[') has 118 occurence\n",
      "merge 201/256: (70, 449) -> 456 (b'Febr') has 118 occurence\n",
      "merge 202/256: (456, 370) -> 457 (b'February ') has 118 occurence\n",
      "merge 203/256: (365, 344) -> 458 (b\"Taylor Swift's \") has 118 occurence\n",
      "merge 204/256: (300, 430) -> 459 (b'\". Billboard') has 118 occurence\n",
      "merge 205/256: (101, 97) -> 460 (b'ea') has 116 occurence\n",
      "merge 206/256: (285, 54) -> 461 (b', 2016') has 116 occurence\n",
      "merge 207/256: (421, 116) -> 462 (b'ept') has 115 occurence\n",
      "merge 208/256: (410, 273) -> 463 (b'May ') has 115 occurence\n",
      "merge 209/256: (285, 53) -> 464 (b', 2015') has 115 occurence\n",
      "merge 210/256: (437, 265) -> 465 (b'Apri') has 115 occurence\n",
      "merge 211/256: (465, 376) -> 466 (b'April ') has 115 occurence\n",
      "merge 212/256: (108, 256) -> 467 (b'le ') has 113 occurence\n",
      "merge 213/256: (65, 119) -> 468 (b'Aw') has 112 occurence\n",
      "merge 214/256: (388, 264) -> 469 (b'ation') has 112 occurence\n",
      "merge 215/256: (83, 462) -> 470 (b'Sept') has 112 occurence\n",
      "merge 216/256: (470, 314) -> 471 (b'September ') has 112 occurence\n",
      "merge 217/256: (114, 97) -> 472 (b'ra') has 111 occurence\n",
      "merge 218/256: (274, 406) -> 473 (b'album') has 111 occurence\n",
      "merge 219/256: (67, 104) -> 474 (b'Ch') has 110 occurence\n",
      "merge 220/256: (118, 256) -> 475 (b've ') has 109 occurence\n",
      "merge 221/256: (310, 266) -> 476 (b'est ') has 108 occurence\n",
      "merge 222/256: (74, 270) -> 477 (b'Jan') has 108 occurence\n",
      "merge 223/256: (50, 50) -> 478 (b'22') has 107 occurence\n",
      "merge 224/256: (477, 370) -> 479 (b'January ') has 107 occurence\n",
      "merge 225/256: (405, 366) -> 480 (b'ountr') has 106 occurence\n",
      "merge 226/256: (382, 104) -> 481 (b'igh') has 106 occurence\n",
      "merge 227/256: (300, 354) -> 482 (b'\". The ') has 106 occurence\n",
      "merge 228/256: (359, 304) -> 483 (b', 2023.\\n ') has 106 occurence\n",
      "merge 229/256: (49, 51) -> 484 (b'13') has 105 occurence\n",
      "merge 230/256: (65, 108) -> 485 (b'Al') has 105 occurence\n",
      "merge 231/256: (101, 116) -> 486 (b'et') has 105 occurence\n",
      "merge 232/256: (310, 115) -> 487 (b'ess') has 103 occurence\n",
      "merge 233/256: (452, 403) -> 488 (b'March ') has 103 occurence\n",
      "merge 234/256: (117, 116) -> 489 (b'ut') has 102 occurence\n",
      "merge 235/256: (119, 431) -> 490 (b'writ') has 101 occurence\n",
      "merge 236/256: (108, 111) -> 491 (b'lo') has 99 occurence\n",
      "merge 237/256: (115, 386) -> 492 (b'song') has 97 occurence\n",
      "merge 238/256: (226, 128) -> 493 (b'\\xe2\\x80') has 97 occurence\n",
      "merge 239/256: (271, 258) -> 494 (b'ard ') has 97 occurence\n",
      "merge 240/256: (48, 32) -> 495 (b'0 ') has 97 occurence\n",
      "merge 241/256: (117, 108) -> 496 (b'ul') has 96 occurence\n",
      "merge 242/256: (50, 52) -> 497 (b'24') has 95 occurence\n",
      "merge 243/256: (105, 262) -> 498 (b'is ') has 94 occurence\n",
      "merge 244/256: (298, 99) -> 499 (b'tic') has 93 occurence\n",
      "merge 245/256: (97, 103) -> 500 (b'ag') has 93 occurence\n",
      "merge 246/256: (34, 32) -> 501 (b'\" ') has 93 occurence\n",
      "merge 247/256: (65, 110) -> 502 (b'An') has 93 occurence\n",
      "merge 248/256: (49, 56) -> 503 (b'18') has 93 occurence\n",
      "merge 249/256: (102, 291) -> 504 (b'for') has 90 occurence\n",
      "merge 250/256: (480, 273) -> 505 (b'ountry ') has 89 occurence\n",
      "merge 251/256: (65, 420) -> 506 (b'Ame') has 88 occurence\n",
      "merge 252/256: (506, 453) -> 507 (b'Americ') has 88 occurence\n",
      "merge 253/256: (32, 84) -> 508 (b' T') has 88 occurence\n",
      "merge 254/256: (115, 296) -> 509 (b'sing') has 87 occurence\n",
      "merge 255/256: (119, 348) -> 510 (b'was ') has 86 occurence\n",
      "merge 256/256: (49, 50) -> 511 (b'12') has 86 occurence\n",
      "merge 1/256: (101, 114) -> 256 (b'er') has 2359 occurence\n",
      "merge 2/256: (50, 48) -> 257 (b'20') has 2187 occurence\n",
      "merge 3/256: (111, 114) -> 258 (b'or') has 2076 occurence\n",
      "merge 4/256: (105, 110) -> 259 (b'in') has 2006 occurence\n",
      "merge 5/256: (101, 100) -> 260 (b'ed') has 1876 occurence\n",
      "merge 6/256: (32, 116) -> 261 (b' t') has 1824 occurence\n",
      "merge 7/256: (111, 110) -> 262 (b'on') has 1815 occurence\n",
      "merge 8/256: (104, 101) -> 263 (b'he') has 1772 occurence\n",
      "merge 9/256: (32, 83) -> 264 (b' S') has 1633 occurence\n",
      "merge 10/256: (97, 114) -> 265 (b'ar') has 1519 occurence\n",
      "merge 11/256: (97, 110) -> 266 (b'an') has 1487 occurence\n",
      "merge 12/256: (32, 65) -> 267 (b' A') has 1335 occurence\n",
      "merge 13/256: (261, 263) -> 268 (b' the') has 1169 occurence\n",
      "merge 14/256: (97, 108) -> 269 (b'al') has 1164 occurence\n",
      "merge 15/256: (114, 105) -> 270 (b'ri') has 1156 occurence\n",
      "merge 16/256: (118, 260) -> 271 (b'ved') has 1104 occurence\n",
      "merge 17/256: (115, 116) -> 272 (b'st') has 1089 occurence\n",
      "merge 18/256: (119, 105) -> 273 (b'wi') has 1049 occurence\n",
      "merge 19/256: (32, 82) -> 274 (b' R') has 1045 occurence\n",
      "merge 20/256: (257, 49) -> 275 (b'201') has 981 occurence\n",
      "merge 21/256: (32, 102) -> 276 (b' f') has 967 occurence\n",
      "merge 22/256: (257, 50) -> 277 (b'202') has 952 occurence\n",
      "merge 23/256: (32, 84) -> 278 (b' T') has 934 occurence\n",
      "merge 24/256: (102, 116) -> 279 (b'ft') has 934 occurence\n",
      "merge 25/256: (97, 121) -> 280 (b'ay') has 900 occurence\n",
      "merge 26/256: (32, 34) -> 281 (b' \"') has 882 occurence\n",
      "merge 27/256: (273, 279) -> 282 (b'wift') has 870 occurence\n",
      "merge 28/256: (101, 116) -> 283 (b'et') has 852 occurence\n",
      "merge 29/256: (264, 282) -> 284 (b' Swift') has 817 occurence\n",
      "merge 30/256: (99, 104) -> 285 (b'ch') has 797 occurence\n",
      "merge 31/256: (98, 256) -> 286 (b'ber') has 797 occurence\n",
      "merge 32/256: (97, 116) -> 287 (b'at') has 790 occurence\n",
      "merge 33/256: (111, 109) -> 288 (b'om') has 789 occurence\n",
      "merge 34/256: (101, 115) -> 289 (b'es') has 743 occurence\n",
      "merge 35/256: (101, 110) -> 290 (b'en') has 724 occurence\n",
      "merge 36/256: (101, 109) -> 291 (b'em') has 699 occurence\n",
      "merge 37/256: (34, 46) -> 292 (b'\".') has 693 occurence\n",
      "merge 38/256: (32, 40) -> 293 (b' (') has 685 occurence\n",
      "merge 39/256: (46, 10) -> 294 (b'.\\n') has 684 occurence\n",
      "merge 40/256: (259, 103) -> 295 (b'ing') has 684 occurence\n",
      "merge 41/256: (108, 258) -> 296 (b'lor') has 680 occurence\n",
      "merge 42/256: (32, 77) -> 297 (b' M') has 662 occurence\n",
      "merge 43/256: (105, 103) -> 298 (b'ig') has 655 occurence\n",
      "merge 44/256: (32, 262) -> 299 (b' on') has 654 occurence\n",
      "merge 45/256: (280, 296) -> 300 (b'aylor') has 650 occurence\n",
      "merge 46/256: (108, 108) -> 301 (b'll') has 649 occurence\n",
      "merge 47/256: (270, 101) -> 302 (b'rie') has 646 occurence\n",
      "merge 48/256: (274, 283) -> 303 (b' Ret') has 643 occurence\n",
      "merge 49/256: (303, 302) -> 304 (b' Retrie') has 639 occurence\n",
      "merge 50/256: (304, 271) -> 305 (b' Retrieved') has 639 occurence\n",
      "merge 51/256: (32, 115) -> 306 (b' s') has 609 occurence\n",
      "merge 52/256: (105, 99) -> 307 (b'ic') has 593 occurence\n",
      "merge 53/256: (266, 100) -> 308 (b'and') has 573 occurence\n",
      "merge 54/256: (111, 117) -> 309 (b'ou') has 555 occurence\n",
      "merge 55/256: (101, 99) -> 310 (b'ec') has 554 occurence\n",
      "merge 56/256: (32, 97) -> 311 (b' a') has 553 occurence\n",
      "merge 57/256: (41, 46) -> 312 (b').') has 533 occurence\n",
      "merge 58/256: (114, 288) -> 313 (b'rom') has 532 occurence\n",
      "merge 59/256: (32, 66) -> 314 (b' B') has 530 occurence\n",
      "merge 60/256: (291, 286) -> 315 (b'ember') has 529 occurence\n",
      "merge 61/256: (32, 111) -> 316 (b' o') has 527 occurence\n",
      "merge 62/256: (276, 313) -> 317 (b' from') has 503 occurence\n",
      "merge 63/256: (267, 114) -> 318 (b' Ar') has 495 occurence\n",
      "merge 64/256: (32, 308) -> 319 (b' and') has 480 occurence\n",
      "merge 65/256: (32, 67) -> 320 (b' C') has 472 occurence\n",
      "merge 66/256: (32, 78) -> 321 (b' N') has 472 occurence\n",
      "merge 67/256: (32, 258) -> 322 (b' or') has 465 occurence\n",
      "merge 68/256: (285, 105) -> 323 (b'chi') has 458 occurence\n",
      "merge 69/256: (32, 74) -> 324 (b' J') has 457 occurence\n",
      "merge 70/256: (259, 269) -> 325 (b'inal') has 456 occurence\n",
      "merge 71/256: (322, 298) -> 326 (b' orig') has 448 occurence\n",
      "merge 72/256: (326, 325) -> 327 (b' original') has 446 occurence\n",
      "merge 73/256: (318, 323) -> 328 (b' Archi') has 440 occurence\n",
      "merge 74/256: (328, 271) -> 329 (b' Archived') has 440 occurence\n",
      "merge 75/256: (316, 102) -> 330 (b' of') has 439 occurence\n",
      "merge 76/256: (32, 104) -> 331 (b' h') has 432 occurence\n",
      "merge 77/256: (32, 259) -> 332 (b' in') has 404 occurence\n",
      "merge 78/256: (114, 101) -> 333 (b're') has 403 occurence\n",
      "merge 79/256: (84, 300) -> 334 (b'Taylor') has 392 occurence\n",
      "merge 80/256: (105, 116) -> 335 (b'it') has 386 occurence\n",
      "merge 81/256: (97, 115) -> 336 (b'as') has 384 occurence\n",
      "merge 82/256: (32, 112) -> 337 (b' p') has 381 occurence\n",
      "merge 83/256: (105, 262) -> 338 (b'ion') has 381 occurence\n",
      "merge 84/256: (32, 68) -> 339 (b' D') has 380 occurence\n",
      "merge 85/256: (32, 119) -> 340 (b' w') has 380 occurence\n",
      "merge 86/256: (265, 100) -> 341 (b'ard') has 374 occurence\n",
      "merge 87/256: (105, 301) -> 342 (b'ill') has 371 occurence\n",
      "merge 88/256: (39, 115) -> 343 (b\"'s\") has 368 occurence\n",
      "merge 89/256: (32, 109) -> 344 (b' m') has 359 occurence\n",
      "merge 90/256: (32, 70) -> 345 (b' F') has 356 occurence\n",
      "merge 91/256: (32, 87) -> 346 (b' W') has 353 occurence\n",
      "merge 92/256: (108, 101) -> 347 (b'le') has 345 occurence\n",
      "merge 93/256: (261, 111) -> 348 (b' to') has 340 occurence\n",
      "merge 94/256: (32, 99) -> 349 (b' c') has 340 occurence\n",
      "merge 95/256: (46, 91) -> 350 (b'.[') has 332 occurence\n",
      "merge 96/256: (111, 118) -> 351 (b'ov') has 317 occurence\n",
      "merge 97/256: (108, 121) -> 352 (b'ly') has 314 occurence\n",
      "merge 98/256: (117, 115) -> 353 (b'us') has 312 occurence\n",
      "merge 99/256: (32, 72) -> 354 (b' H') has 310 occurence\n",
      "merge 100/256: (105, 115) -> 355 (b'is') has 307 occurence\n",
      "merge 101/256: (32, 80) -> 356 (b' P') has 302 occurence\n",
      "merge 102/256: (116, 104) -> 357 (b'th') has 290 occurence\n",
      "merge 103/256: (99, 116) -> 358 (b'ct') has 282 occurence\n",
      "merge 104/256: (117, 109) -> 359 (b'um') has 281 occurence\n",
      "merge 105/256: (32, 98) -> 360 (b' b') has 280 occurence\n",
      "merge 106/256: (32, 71) -> 361 (b' G') has 277 occurence\n",
      "merge 107/256: (265, 121) -> 362 (b'ary') has 267 occurence\n",
      "merge 108/256: (32, 73) -> 363 (b' I') has 264 occurence\n",
      "merge 109/256: (278, 300) -> 364 (b' Taylor') has 255 occurence\n",
      "merge 110/256: (105, 272) -> 365 (b'ist') has 248 occurence\n",
      "merge 111/256: (32, 100) -> 366 (b' d') has 247 occurence\n",
      "merge 112/256: (97, 109) -> 367 (b'am') has 247 occurence\n",
      "merge 113/256: (32, 79) -> 368 (b' O') has 247 occurence\n",
      "merge 114/256: (111, 112) -> 369 (b'op') has 243 occurence\n",
      "merge 115/256: (324, 117) -> 370 (b' Ju') has 239 occurence\n",
      "merge 116/256: (331, 256) -> 371 (b' her') has 235 occurence\n",
      "merge 117/256: (32, 76) -> 372 (b' L') has 228 occurence\n",
      "merge 118/256: (117, 272) -> 373 (b'ust') has 228 occurence\n",
      "merge 119/256: (97, 100) -> 374 (b'ad') has 225 occurence\n",
      "merge 120/256: (278, 263) -> 375 (b' The') has 225 occurence\n",
      "merge 121/256: (117, 362) -> 376 (b'uary') has 225 occurence\n",
      "merge 122/256: (290, 116) -> 377 (b'ent') has 223 occurence\n",
      "merge 123/256: (353, 307) -> 378 (b'usic') has 221 occurence\n",
      "merge 124/256: (351, 315) -> 379 (b'ovember') has 221 occurence\n",
      "merge 125/256: (101, 119) -> 380 (b'ew') has 216 occurence\n",
      "merge 126/256: (256, 115) -> 381 (b'ers') has 215 occurence\n",
      "merge 127/256: (265, 116) -> 382 (b'art') has 204 occurence\n",
      "merge 128/256: (105, 100) -> 383 (b'id') has 204 occurence\n",
      "merge 129/256: (32, 69) -> 384 (b' E') has 203 occurence\n",
      "merge 130/256: (101, 108) -> 385 (b'el') has 203 occurence\n",
      "merge 131/256: (262, 103) -> 386 (b'ong') has 202 occurence\n",
      "merge 132/256: (105, 109) -> 387 (b'im') has 202 occurence\n",
      "merge 133/256: (111, 286) -> 388 (b'ober') has 202 occurence\n",
      "merge 134/256: (101, 112) -> 389 (b'ep') has 201 occurence\n",
      "merge 135/256: (276, 258) -> 390 (b' for') has 199 occurence\n",
      "merge 136/256: (358, 388) -> 391 (b'ctober') has 198 occurence\n",
      "merge 137/256: (98, 111) -> 392 (b'bo') has 197 occurence\n",
      "merge 138/256: (314, 342) -> 393 (b' Bill') has 196 occurence\n",
      "merge 139/256: (310, 315) -> 394 (b'ecember') has 195 occurence\n",
      "merge 140/256: (264, 116) -> 395 (b' St') has 195 occurence\n",
      "merge 141/256: (392, 341) -> 396 (b'board') has 192 occurence\n",
      "merge 142/256: (111, 119) -> 397 (b'ow') has 186 occurence\n",
      "merge 143/256: (117, 103) -> 398 (b'ug') has 185 occurence\n",
      "merge 144/256: (111, 116) -> 399 (b'ot') has 184 occurence\n",
      "merge 145/256: (393, 396) -> 400 (b' Billboard') has 184 occurence\n",
      "merge 146/256: (49, 48) -> 401 (b'10') has 183 occurence\n",
      "merge 147/256: (110, 116) -> 402 (b'nt') has 182 occurence\n",
      "merge 148/256: (110, 101) -> 403 (b'ne') has 182 occurence\n",
      "merge 149/256: (101, 265) -> 404 (b'ear') has 179 occurence\n",
      "merge 150/256: (309, 114) -> 405 (b'our') has 179 occurence\n",
      "merge 151/256: (270, 116) -> 406 (b'rit') has 177 occurence\n",
      "merge 152/256: (105, 114) -> 407 (b'ir') has 176 occurence\n",
      "merge 153/256: (98, 359) -> 408 (b'bum') has 172 occurence\n",
      "merge 154/256: (117, 114) -> 409 (b'ur') has 171 occurence\n",
      "merge 155/256: (287, 338) -> 410 (b'ation') has 171 occurence\n",
      "merge 156/256: (257, 48) -> 411 (b'200') has 171 occurence\n",
      "merge 157/256: (111, 108) -> 412 (b'ol') has 168 occurence\n",
      "merge 158/256: (289, 115) -> 413 (b'ess') has 166 occurence\n",
      "merge 159/256: (32, 114) -> 414 (b' r') has 164 occurence\n",
      "merge 160/256: (93, 91) -> 415 (b'][') has 164 occurence\n",
      "merge 161/256: (398, 373) -> 416 (b'ugust') has 164 occurence\n",
      "merge 162/256: (32, 86) -> 417 (b' V') has 161 occurence\n",
      "merge 163/256: (32, 39) -> 418 (b\" '\") has 160 occurence\n",
      "merge 164/256: (101, 98) -> 419 (b'eb') has 157 occurence\n",
      "merge 165/256: (32, 269) -> 420 (b' al') has 153 occurence\n",
      "merge 166/256: (105, 118) -> 421 (b'iv') has 152 occurence\n",
      "merge 167/256: (32, 89) -> 422 (b' Y') has 152 occurence\n",
      "merge 168/256: (117, 116) -> 423 (b'ut') has 151 occurence\n",
      "merge 169/256: (32, 273) -> 424 (b' wi') has 150 occurence\n",
      "merge 170/256: (114, 121) -> 425 (b'ry') has 149 occurence\n",
      "merge 171/256: (101, 272) -> 426 (b'est') has 144 occurence\n",
      "merge 172/256: (424, 357) -> 427 (b' with') has 143 occurence\n",
      "merge 173/256: (114, 97) -> 428 (b'ra') has 141 occurence\n",
      "merge 174/256: (339, 394) -> 429 (b' December') has 140 occurence\n",
      "merge 175/256: (321, 379) -> 430 (b' November') has 138 occurence\n",
      "merge 176/256: (32, 287) -> 431 (b' at') has 133 occurence\n",
      "merge 177/256: (32, 333) -> 432 (b' re') has 130 occurence\n",
      "merge 178/256: (370, 352) -> 433 (b' July') has 129 occurence\n",
      "merge 179/256: (261, 104) -> 434 (b' th') has 127 occurence\n",
      "merge 180/256: (32, 110) -> 435 (b' n') has 127 occurence\n",
      "merge 181/256: (267, 416) -> 436 (b' August') has 127 occurence\n",
      "merge 182/256: (258, 100) -> 437 (b'ord') has 126 occurence\n",
      "merge 183/256: (119, 341) -> 438 (b'ward') has 125 occurence\n",
      "merge 184/256: (49, 57) -> 439 (b'19') has 125 occurence\n",
      "merge 185/256: (32, 75) -> 440 (b' K') has 125 occurence\n",
      "merge 186/256: (368, 391) -> 441 (b' October') has 125 occurence\n",
      "merge 187/256: (32, 108) -> 442 (b' l') has 123 occurence\n",
      "merge 188/256: (111, 301) -> 443 (b'oll') has 122 occurence\n",
      "merge 189/256: (112, 270) -> 444 (b'pri') has 122 occurence\n",
      "merge 190/256: (117, 108) -> 445 (b'ul') has 121 occurence\n",
      "merge 191/256: (389, 116) -> 446 (b'ept') has 121 occurence\n",
      "merge 192/256: (297, 378) -> 447 (b' Music') has 119 occurence\n",
      "merge 193/256: (32, 85) -> 448 (b' U') has 119 occurence\n",
      "merge 194/256: (111, 115) -> 449 (b'os') has 119 occurence\n",
      "merge 195/256: (419, 114) -> 450 (b'ebr') has 119 occurence\n",
      "merge 196/256: (311, 115) -> 451 (b' as') has 118 occurence\n",
      "merge 197/256: (110, 100) -> 452 (b'nd') has 118 occurence\n",
      "merge 198/256: (44, 91) -> 453 (b',[') has 118 occurence\n",
      "merge 199/256: (450, 376) -> 454 (b'ebruary') has 118 occurence\n",
      "merge 200/256: (321, 380) -> 455 (b' New') has 117 occurence\n",
      "merge 201/256: (32, 272) -> 456 (b' st') has 116 occurence\n",
      "merge 202/256: (111, 100) -> 457 (b'od') has 115 occurence\n",
      "merge 203/256: (97, 107) -> 458 (b'ak') has 115 occurence\n",
      "merge 204/256: (444, 108) -> 459 (b'pril') has 115 occurence\n",
      "merge 205/256: (309, 402) -> 460 (b'ount') has 114 occurence\n",
      "merge 206/256: (320, 104) -> 461 (b' Ch') has 114 occurence\n",
      "merge 207/256: (99, 101) -> 462 (b'ce') has 113 occurence\n",
      "merge 208/256: (446, 315) -> 463 (b'eptember') has 112 occurence\n",
      "merge 209/256: (420, 408) -> 464 (b' album') has 110 occurence\n",
      "merge 210/256: (105, 108) -> 465 (b'il') has 109 occurence\n",
      "merge 211/256: (267, 438) -> 466 (b' Award') has 108 occurence\n",
      "merge 212/256: (310, 437) -> 467 (b'ecord') has 108 occurence\n",
      "merge 213/256: (266, 376) -> 468 (b'anuary') has 107 occurence\n",
      "merge 214/256: (49, 51) -> 469 (b'13') has 106 occurence\n",
      "merge 215/256: (460, 425) -> 470 (b'ountry') has 106 occurence\n",
      "merge 216/256: (109, 256) -> 471 (b'mer') has 105 occurence\n",
      "merge 217/256: (262, 101) -> 472 (b'one') has 105 occurence\n",
      "merge 218/256: (32, 103) -> 473 (b' g') has 104 occurence\n",
      "merge 219/256: (50, 49) -> 474 (b'21') has 103 occurence\n",
      "merge 220/256: (265, 285) -> 475 (b'arch') has 103 occurence\n",
      "merge 221/256: (111, 99) -> 476 (b'oc') has 101 occurence\n",
      "merge 222/256: (310, 116) -> 477 (b'ect') has 100 occurence\n",
      "merge 223/256: (105, 97) -> 478 (b'ia') has 98 occurence\n",
      "merge 224/256: (118, 256) -> 479 (b'ver') has 98 occurence\n",
      "merge 225/256: (226, 128) -> 480 (b'\\xe2\\x80') has 97 occurence\n",
      "merge 226/256: (264, 263) -> 481 (b' She') has 96 occurence\n",
      "merge 227/256: (297, 280) -> 482 (b' May') has 96 occurence\n",
      "merge 228/256: (267, 108) -> 483 (b' Al') has 95 occurence\n",
      "merge 229/256: (50, 51) -> 484 (b'23') has 95 occurence\n",
      "merge 230/256: (370, 403) -> 485 (b' June') has 95 occurence\n",
      "merge 231/256: (344, 378) -> 486 (b' music') has 94 occurence\n",
      "merge 232/256: (49, 56) -> 487 (b'18') has 93 occurence\n",
      "merge 233/256: (278, 387) -> 488 (b' Tim') has 91 occurence\n",
      "merge 234/256: (421, 101) -> 489 (b'ive') has 90 occurence\n",
      "merge 235/256: (345, 454) -> 490 (b' February') has 90 occurence\n",
      "merge 236/256: (101, 101) -> 491 (b'ee') has 89 occurence\n",
      "merge 237/256: (105, 266) -> 492 (b'ian') has 89 occurence\n",
      "merge 238/256: (50, 52) -> 493 (b'24') has 89 occurence\n",
      "merge 239/256: (471, 307) -> 494 (b'meric') has 88 occurence\n",
      "merge 240/256: (49, 50) -> 495 (b'12') has 87 occurence\n",
      "merge 241/256: (264, 463) -> 496 (b' September') has 87 occurence\n",
      "merge 242/256: (306, 295) -> 497 (b' sing') has 86 occurence\n",
      "merge 243/256: (32, 118) -> 498 (b' v') has 86 occurence\n",
      "merge 244/256: (340, 336) -> 499 (b' was') has 86 occurence\n",
      "merge 245/256: (267, 459) -> 500 (b' April') has 86 occurence\n",
      "merge 246/256: (49, 55) -> 501 (b'17') has 84 occurence\n",
      "merge 247/256: (50, 50) -> 502 (b'22') has 84 occurence\n",
      "merge 248/256: (111, 103) -> 503 (b'og') has 83 occurence\n",
      "merge 249/256: (119, 406) -> 504 (b'writ') has 83 occurence\n",
      "merge 250/256: (78, 379) -> 505 (b'November') has 83 occurence\n",
      "merge 251/256: (306, 386) -> 506 (b' song') has 82 occurence\n",
      "merge 252/256: (49, 52) -> 507 (b'14') has 82 occurence\n",
      "merge 253/256: (298, 104) -> 508 (b'igh') has 82 occurence\n",
      "merge 254/256: (108, 100) -> 509 (b'ld') has 82 occurence\n",
      "merge 255/256: (93, 10) -> 510 (b']\\n') has 82 occurence\n",
      "merge 256/256: (306, 263) -> 511 (b' she') has 82 occurence\n",
      "Training took 35.41 seconds\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "\n",
    "\n",
    "txt = open('taylorswift.txt', 'r', encoding='utf-8').read()\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "t0 = time.time()\n",
    "for TokenizerClass, name in zip([BasicTokenizer, RegExTokenizer], ['basic', 'regex']):\n",
    "    tokenizr = TokenizerClass()\n",
    "    tokenizr.train(txt, 512, verbose=True)\n",
    "\n",
    "    prefx = os.path.join(\"models\", name)\n",
    "    tokenizr.save(prefx)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"Training took {t1 - t0:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    " + You're now ready to load the merges from the GPT-4 tokenizer and show that your tokenizer produces the identical results for both encode and decode, matching tiktoken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [15339, 1917, 12340, 30, 320, 31495, 230, 75265, 243, 92245, 16715, 28509, 4513, 57037]\n",
      "Decoded Text: hello world!!!? (안녕하세요!) lol123 😉\n"
     ]
    }
   ],
   "source": [
    "# match this\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\") # this is the GPT-4 tokenizer\n",
    "ids = enc.encode(\"hello world!!!? (안녕하세요!) lol123 😉\")\n",
    "text = enc.decode(ids) # get the same text back\n",
    "\n",
    "print(\"Token IDs:\", ids)\n",
    "print(\"Decoded Text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: hello world!!!? (안녕하세요!) lol123 😉\n",
      "Regex Tokenizer IDs: [104, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100, 33, 33, 33, 63, 32, 40, 236, 149, 136, 235, 133, 149, 237, 149, 152, 236, 132, 184, 236, 154, 148, 33, 41, 32, 108, 111, 108, 49, 50, 51, 32, 240, 159, 152, 137]\n",
      "Regex Decoded Text: hello world!!!? (안녕하세요!) lol123 😉\n"
     ]
    }
   ],
   "source": [
    "# GPT-4 regex pattern\n",
    "GPT4_SPLIT_PATTERN = r\"\"\"'(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "# Instantiate RegexTokenizer\n",
    "regexToknizr  = RegExTokenizer(GPT4_SPLIT_PATTERN)\n",
    "\n",
    "# Encode and decode\n",
    "regXids = regexToknizr.enc(text)\n",
    "regexDecodTxt = regexToknizr.decod(regXids)\n",
    "\n",
    "# Print the results\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Regex Tokenizer IDs:\", regXids)\n",
    "print(\"Regex Decoded Text:\", regexDecodTxt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert text == regexDecodTxt, \"Decoded text doesn't match the original!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

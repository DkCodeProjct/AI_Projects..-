Andrej Lecture on:  
#The spelled-out intro to neural networks and backpropagation: building micrograd
....

### Its good to watch Statquest NN sereis first so that user can undersatnd derivatives/The Chain Rule So on...

  * so i think i got more sense about NN cos Andrej did prety goog job explaining it... and i wish i could more work on that
    derivaties and chain rule [I didn't cos im in a hurry (Ok im being lazy or what ever) ]
  * but No need to evrything at once,, while im not doing Calculas stuff also back in my head i know
    i would come later and lay the good foundation ,, and prety much my whole Learning journy has been like that
  * when i learned python i didnt learn it all once i was just playing around and when i got Focus im just getting the Job Don

#### :: And so Thank's to andrej i got more sense about backprop/MLP/Calculating Loss
  
  * i think i should do more study on Loss func, backward, topological sorting and stuff.

# Thank You Anderj ;)
